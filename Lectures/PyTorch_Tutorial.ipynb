{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6oqGiIXvrMl"
   },
   "source": [
    "# PyTorch Tutorial\n",
    "\n",
    "Adapted from Stanford CS224N, by\n",
    "### Author: Dilara Soylu\n",
    "\n",
    "In this notebook, we will have a basic introduction to `PyTorch` and work on a toy NLP task. Following resources have been used in preparation of this notebook:\n",
    "* [\"Word Window Classification\" tutorial notebook]((https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1204/materials/ww_classifier.ipynb) by Matt Lamm, from Winter 2020 offering of CS224N\n",
    "* Official PyTorch Documentation on [Deep Learning with PyTorch: A 60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) by Soumith Chintala\n",
    "* PyTorch Tutorial Notebook, [Build Basic Generative Adversarial Networks (GANs) | Coursera](https://www.coursera.org/learn/build-basic-generative-adversarial-networks-gans) by Sharon Zhou, offered on Coursera\n",
    "\n",
    "Many thanks to Angelica Sun and John Hewitt for their feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gk1UKaNvrMv"
   },
   "source": [
    "## Introduction\n",
    "[PyTorch](https://pytorch.org/) is a machine learning framework that is used in both academia and industry for various applications. PyTorch started of as a more flexible alternative to [TensorFlow](https://www.tensorflow.org/), which is another popular machine learning framework. At the time of its release, `PyTorch` appealed to the users due to its user friendly nature: as opposed to defining static graphs before performing an operation as in `TensorFlow`, `PyTorch` allowed users to define their operations as they go, which is also the approached integrated by `TensorFlow` in its following releases. Although `TensorFlow` is more widely preferred in the industry, `PyTorch` is often times the preferred machine learning framework for researchers. If you would like to learn more about the differences between the two, you can check out [this](https://blog.udacity.com/2020/05/pytorch-vs-tensorflow-what-you-need-to-know.html) blog post. \n",
    "\n",
    "Now that we have learned enough about the background of `PyTorch`, let's start by importing it into our notebook. To install `PyTorch`, you can follow the instructions here. Alternatively, you can open this notebook using `Google Colab`, which already has `PyTorch` installed in its base kernel. Once you are done with the installation process, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u0ukr7quvrMx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Import pprint, module we use for making our print statements prettier\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k10ZRdcBwDP3"
   },
   "source": [
    "We are all set to start our tutorial. Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLdSN9ZXvrM0"
   },
   "source": [
    "## Tensors\n",
    "\n",
    "Tensors are the most basic building blocks in `PyTorch`.  Tensors are similar to matrices, but the have extra properties and they can represent higher dimensions. For example, an square image with 256 pixels in both sides can be represented by a `3x256x256` tensor, where the first 3 dimensions represent the color channels, red, green and blue. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6aWvTEy7lgG"
   },
   "source": [
    "### Tensor Initialization\n",
    "There are several ways to instantiate tensors in `PyTorch`, which we will go through next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c78_3AMEyvJd"
   },
   "source": [
    "#### **From a Python List**\n",
    "\n",
    "We can initalize a tensor from a `Python` list, which could include sublists. The dimensions and the data types will be automatically inferred by `PyTorch` when we use [`torch.tensor()`](https://pytorch.org/docs/stable/generated/torch.tensor.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lsjIW9I_ztiO",
    "outputId": "b78c8e03-211d-499b-9089-262f7ac04b19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a tensor from a Python List\n",
    "data = [\n",
    "        [0, 1], \n",
    "        [2, 3],\n",
    "        [4, 5]\n",
    "       ]\n",
    "x_python = torch.tensor(data)\n",
    "\n",
    "# Print the tensor\n",
    "x_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iv6ZEoZ0RWb5"
   },
   "source": [
    "We can also call `torch.tensor()` with the optional `dtype` parameter, which will set the data type. Some useful datatypes to be familiar with are: `torch.bool`, `torch.float`, and `torch.long`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bQF5IhsD7-n",
    "outputId": "a4729524-2b06-4545-cf1f-f83a5a7574b5"
   },
   "source": [
    "We can use the dtype to create a tensor of particular type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bQF5IhsD7-n",
    "outputId": "a4729524-2b06-4545-cf1f-f83a5a7574b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_float = torch.tensor(data, dtype=torch.float)\n",
    "x_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16VoILaaE-_j",
    "outputId": "8d236b7a-b60e-482c-c28b-df25925d7819"
   },
   "source": [
    "We can use the dtype to create a tensor of particular type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16VoILaaE-_j",
    "outputId": "8d236b7a-b60e-482c-c28b-df25925d7819"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bool = torch.tensor(data, dtype=torch.bool)\n",
    "x_bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4HccPWFEQUB"
   },
   "source": [
    "We can also get the same tensor in our specified data type using methods such as `float()`, `long()` etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nh_yq0SuTS_W",
    "outputId": "f01ac372-5cb4-4be7-ae34-7c0a37b1b444"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_python.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFiS1OFdTlKE"
   },
   "source": [
    "We can also use `tensor.FloatTensor`, `tensor.LongTensor`, `tensor.Tensor` classes to instantiate a tensor of particular type. `LongTensor`s are particularly important in NLP as many methods that deal with indices require the indices to be passed as a `LongTensor`, which is a 64 bit integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXXWZ1H2TkNN",
    "outputId": "66564be9-f6df-4fab-c248-724635a2e272"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `torch.Tensor` defaults to float\n",
    "# Same as torch.FloatTensor(data)\n",
    "x = torch.Tensor(data) \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuLzDzsoytM2"
   },
   "source": [
    "#### **From a NumPy Array**\n",
    "We can also initialize a tensor from a `NumPy` array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtSNe8X-2Pox",
    "outputId": "e0e2222c-27db-485f-a005-9ee3f6463e72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize a tensor from a NumPy array\n",
    "ndarray = np.array(data)\n",
    "x_numpy = torch.from_numpy(ndarray)\n",
    "\n",
    "# Print the tensor\n",
    "x_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhtcBgum3OZ3"
   },
   "source": [
    "#### **From a Tensor**\n",
    "We can also initialize a tensor from another tensor, using the following methods:\n",
    "\n",
    "* `torch.ones_like(old_tensor)`: Initializes a tensor of `1s`.\n",
    "* `torch.zeros_like(old_tensor)`: Initializes a tensor of `0s`.\n",
    "* `torch.rand_like(old_tensor)`: Initializes a tensor where all the elements are sampled from a uniform distribution between `0` and `1`.\n",
    "* `torch.randn_like(old_tensor)`: Initializes a tensor where all the elements are sampled from a normal distribution.\n",
    "\n",
    "All of these methods preserve the tensor properties of the original tensor passed in, such as the `shape` and `device`, which we will cover in a bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zoKVhcLh2yqe",
    "outputId": "8ed9acbe-947b-4890-db81-c83d802c0f86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a base tensor\n",
    "x = torch.tensor([[1., 2], [3, 4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FncfGN6z7ELA",
    "outputId": "71db6165-ea7a-4068-da13-c0310790c4b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a tensor of 0s\n",
    "x_zeros = torch.zeros_like(x)\n",
    "x_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D993dpnP6iA8",
    "outputId": "ca8a7fd3-e7d0-47f7-a7c0-1bddc5614223"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a tensor of 1s\n",
    "x_ones = torch.ones_like(x)\n",
    "x_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBUDeEm97IqW",
    "outputId": "455a2ce8-caf6-4252-c1be-6207e81d2649"
   },
   "source": [
    "Initialize a tensor where each element is sampled from a uniform distribution\n",
    "between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBUDeEm97IqW",
    "outputId": "455a2ce8-caf6-4252-c1be-6207e81d2649"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4053, 0.5043],\n",
       "        [0.2663, 0.6317]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rand = torch.rand_like(x)\n",
    "x_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYsE3lKt7IEX",
    "outputId": "2c49ce88-937e-4afe-eb1c-37a625cbc77f"
   },
   "source": [
    "Initialize a tensor where each element is sampled from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYsE3lKt7IEX",
    "outputId": "2c49ce88-937e-4afe-eb1c-37a625cbc77f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3008, -0.2409],\n",
       "        [ 1.4141,  0.2723]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_randn = torch.randn_like(x)\n",
    "x_randn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6tqf7v38vbi"
   },
   "source": [
    "#### **By Specifying a Shape**\n",
    "We can also instantiate tensors by specifying their shapes (which we will cover in more detail in a bit). The methods we could use follow the ones in the previous section:\n",
    "* `torch.zeros()`\n",
    "* `torch.ones()`\n",
    "* `torch.rand()`\n",
    "* `torch.randn()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dh4I4Npz-dZ4",
    "outputId": "e45a1095-0d18-4266-ceb7-a7c9de1f18e2"
   },
   "source": [
    "Initialize a 2x3x2 tensor of 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dh4I4Npz-dZ4",
    "outputId": "e45a1095-0d18-4266-ceb7-a7c9de1f18e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (4, 2, 2)\n",
    "x_zeros = torch.zeros(shape) # x_zeros = torch.zeros(4, 3, 2) is an alternative\n",
    "x_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LEjeR24MLkN"
   },
   "source": [
    "#### **With `torch.arange()`**\n",
    "We can also create a tensor with `torch.arange(end)`, which returns a `1-D` tensor with elements ranging from `0` to `end-1`. We can use the optional `start` and `step` parameters to create tensors with different ranges.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EjARl2aM7pA",
    "outputId": "264a9ffa-5d05-4b9d-9901-cd49cbb93264"
   },
   "source": [
    "Create a tensor with values 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EjARl2aM7pA",
    "outputId": "264a9ffa-5d05-4b9d-9901-cd49cbb93264"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgpkRn527zSr"
   },
   "source": [
    "### Tensor Properties\n",
    "\n",
    "Tensors have a few properties that are important for us to cover. These are namely `shape`, and the `device` properties. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBt6e4xZT3zr"
   },
   "source": [
    "#### Data Type\n",
    "\n",
    "The `dtype` property lets us see the data type of a tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rlF3k3eUT_hQ",
    "outputId": "c2416faf-77cc-46e9-a22e-a67fe14bc13d"
   },
   "source": [
    "Initialize a 3x2 tensor, with 3 rows and 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rlF3k3eUT_hQ",
    "outputId": "c2416faf-77cc-46e9-a22e-a67fe14bc13d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(3, 2)\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1vtN4Dy8FAG"
   },
   "source": [
    "#### Shape\n",
    "\n",
    "The `shape` property tells us the shape of our tensor. This can help us identify how many dimensional our tensor is as well as how many elements exist in each dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24gXLJcn7Pxs",
    "outputId": "ef11b998-9fc4-458e-8452-6d545da19694"
   },
   "source": [
    "Initialize a 3x2 tensor, with 3 rows and 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24gXLJcn7Pxs",
    "outputId": "ef11b998-9fc4-458e-8452-6d545da19694"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 2], [3, 4], [5, 6]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vV0cE1cXAEHP",
    "outputId": "1d12cf8d-c659-4127-807e-91459ba12d3a"
   },
   "source": [
    "Print out its shape: same as x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vV0cE1cXAEHP",
    "outputId": "1d12cf8d-c659-4127-807e-91459ba12d3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MA3vnJnaAQlc",
    "outputId": "cfa251e1-be1c-4dbc-9803-bc213ca05a2a"
   },
   "source": [
    "Print out the number of elements in a particular dimension. \n",
    "0th dimension corresponds to the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MA3vnJnaAQlc",
    "outputId": "cfa251e1-be1c-4dbc-9803-bc213ca05a2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxXCX6y6BvhH"
   },
   "source": [
    "We can also get the size of a particular dimension with the `size()` method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZapQmydxBVuy",
    "outputId": "24547ccf-817c-44ef-bc6a-03a0bf246a58"
   },
   "source": [
    "Get the size of the 0th dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZapQmydxBVuy",
    "outputId": "24547ccf-817c-44ef-bc6a-03a0bf246a58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCQm7ToPOveH"
   },
   "source": [
    "We can change the shape of a tensor with the `view()` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1JH3fiNO5Gu",
    "outputId": "0c270810-811b-466f-a5d2-70f240942aa3"
   },
   "source": [
    "x_view shares the same memory as x, so changing one changes the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1JH3fiNO5Gu",
    "outputId": "0c270810-811b-466f-a5d2-70f240942aa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_view = x.view(2, 3)\n",
    "x_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3C3x4seqPGEI",
    "outputId": "66e48d01-5702-414c-c628-055adbdcdeef"
   },
   "source": [
    "We can ask PyTorch to infer the size of a dimension with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3C3x4seqPGEI",
    "outputId": "66e48d01-5702-414c-c628-055adbdcdeef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_view = x.view(3, -1)\n",
    "x_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYSCEesPITpf"
   },
   "source": [
    "We can also use `torch.reshape()` method for a similar purpose. There is a subtle difference between `reshape()` and `view()`: `view()` requires the data to be stored contiguously in the memory. You can refer to [this](https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch) StackOverflow answer for more information. In simple terms, contiguous means that the way our data is laid out in the memory is the same as the way we would read elements from it. This happens because some methods, such as `transpose()` and `view()`, do not actually change how our data is stored in the memory. They just change the meta information about out tensor, so that when we use it we will see the elements in the order we expect. \n",
    "\n",
    "`reshape()` calls `view()` internally if the data is stored contiguously, if not, it returns a copy. The difference here isn't too important for basic tensors, but if you perform operations that make the underlying storage of the data non-contiguous (such as taking a transpose), you will have issues using `view()`. If you would like to match the way your tensor is stored in the memory to how it is used, you can use the `contiguous()` method.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLGcGYE4Llom",
    "outputId": "e810557b-552f-4b0f-a37a-1924bec7fcfa"
   },
   "source": [
    "Change the shape of x to be 3x2.\n",
    "x_reshaped could be a reference to or copy of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLGcGYE4Llom",
    "outputId": "e810557b-552f-4b0f-a37a-1924bec7fcfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = torch.reshape(x, (2, 3))\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWNTZKZZQ9i6"
   },
   "source": [
    "We can use `torch.unsqueeze(x, dim)` function to add a dimension of size `1` to the provided `dim`, where `x` is the tensor. We can also use the corresponding use `torch.squeeze(x)`, which removes the dimensions of size `1`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_IYojrJRh-m",
    "outputId": "ed315529-ea33-4cbe-9878-4581f3afbcdb"
   },
   "source": [
    "Initialize a 5x2 tensor, with 5 rows and 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_IYojrJRh-m",
    "outputId": "ed315529-ea33-4cbe-9878-4581f3afbcdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(10).reshape(5, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pLhg_oZ4SHh-",
    "outputId": "a32cf8a3-c1f4-4220-d948-b42fd12f8772"
   },
   "source": [
    "Add a new dimension of size 1 at the 1st dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pLhg_oZ4SHh-",
    "outputId": "a32cf8a3-c1f4-4220-d948-b42fd12f8772"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.unsqueeze(1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YoGYGbMRSo-J",
    "outputId": "9c8415c4-ebf3-40ab-9faa-b13c5fd42c62"
   },
   "source": [
    "Squeeze the dimensions of x by getting rid of all the dimensions with 1 element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YoGYGbMRSo-J",
    "outputId": "9c8415c4-ebf3-40ab-9faa-b13c5fd42c62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.squeeze()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQpZ4556B3lb"
   },
   "source": [
    "If we want to get the total number of elements in a tensor, we can use the `numel()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76yVMMg_CA0Q",
    "outputId": "7edfbc68-b830-459c-a5bf-fe3803a902af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_M1U_RTpBhl2"
   },
   "source": [
    "#### **Device**\n",
    "Device property tells `PyTorch` where to store our tensor. Where a tensor is stored determines which device, `GPU` or `CPU`, would be handling the computations involving it. We can find the device of a tensor with the `device` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYRGhIbnCl3b",
    "outputId": "4eac92c3-48f5-4e4e-cdf1-329bd79538b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an example tensor\n",
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "byEnJyKdBgjl",
    "outputId": "04440390-a16d-4250-920e-64dade75622a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the device of the tensor\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vqf_-NADFX8"
   },
   "source": [
    "We can move a tensor from one device to another with the method `to(device)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "GzA6zqkXDEt1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available, if so, move the tensor to the GPU\n",
    "if torch.cuda.is_available():\n",
    "  x.to('cuda') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7BMktFFAkRA"
   },
   "source": [
    "### Tensor Indexing\n",
    "In `PyTorch` we can index tensors, similar to `NumPy`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRJN7ovWDsKV",
    "outputId": "f4bea081-d4c4-49a2-e529-fa502cf135f7"
   },
   "source": [
    "Create a tensor from a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRJN7ovWDsKV",
    "outputId": "f4bea081-d4c4-49a2-e529-fa502cf135f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.],\n",
       "         [ 3.,  4.]],\n",
       "\n",
       "        [[ 5.,  6.],\n",
       "         [ 7.,  8.]],\n",
       "\n",
       "        [[ 9., 10.],\n",
       "         [11., 12.]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([\n",
    "                  [[1, 2], [3, 4]],\n",
    "                  [[5, 6], [7, 8]], \n",
    "                  [[9, 10], [11, 12]] \n",
    "                 ])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M67ZiOF1Heyc",
    "outputId": "0821f0cc-5a93-46e6-bee4-9fd648723a27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guXKE7m8AX1K",
    "outputId": "cf492c27-a67d-4fbe-b57a-54fb4f8802a4"
   },
   "source": [
    "Access the 0th element, which is the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guXKE7m8AX1K",
    "outputId": "cf492c27-a67d-4fbe-b57a-54fb4f8802a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # Equivalent to x[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8m8EyVvES4-"
   },
   "source": [
    "We can also index into multiple dimensions with `:`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Z6GFUcuEL85",
    "outputId": "f36a740c-df12-42f6-a64b-d4b3038168f4"
   },
   "source": [
    "Get the top left element of each element in our tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Z6GFUcuEL85",
    "outputId": "f36a740c-df12-42f6-a64b-d4b3038168f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 5., 9.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rm8vc3nuXaEw"
   },
   "source": [
    "We can also access arbitrary elements in each dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4xl6CW3RrEw",
    "outputId": "1cb93869-7764-4d22-b411-dcaadb906830"
   },
   "source": [
    "Let's access the 0th and 1st elements, each twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4xl6CW3RrEw",
    "outputId": "1cb93869-7764-4d22-b411-dcaadb906830"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[5., 6.],\n",
       "         [7., 8.]],\n",
       "\n",
       "        [[5., 6.],\n",
       "         [7., 8.]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.tensor([0, 0, 1, 1])\n",
    "x[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3QYZ8k7Wvqp",
    "outputId": "6cb46909-2800-45a0-abb3-0707c2c50d6c"
   },
   "source": [
    "Let's access the 0th elements of the 1st and 2nd elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3QYZ8k7Wvqp",
    "outputId": "6cb46909-2800-45a0-abb3-0707c2c50d6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.tensor([1, 2])\n",
    "j = torch.tensor([0])\n",
    "x[i, j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAELXC--IHS7"
   },
   "source": [
    "We can get a `Python` scalar value from a tensor with `item()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BM-ZujN2IGaQ",
    "outputId": "785f43c3-5670-4fa2-ed51-e72e9c0474ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NwxK7d_Ycgs",
    "outputId": "343abf96-2d77-49b0-9076-c0f617e7aafe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, 0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GltnmDzeIXJM"
   },
   "source": [
    "### Operations\n",
    "PyTorch operations are very similar to those of `NumPy`. We can work with both scalars and other tensors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9KBzcA0G6v9",
    "outputId": "057decb7-7a56-4fcc-bc20-781cba8d0caf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an example tensor\n",
    "x = torch.ones((3,2,2))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUw8MAHqKuzs",
    "outputId": "fd10173a-caf5-4e45-ceca-c0b32f4bf39e"
   },
   "source": [
    "Perform elementwise addition.<br/>\n",
    "Use - for subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUw8MAHqKuzs",
    "outputId": "fd10173a-caf5-4e45-ceca-c0b32f4bf39e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 3.],\n",
       "         [3., 3.]],\n",
       "\n",
       "        [[3., 3.],\n",
       "         [3., 3.]],\n",
       "\n",
       "        [[3., 3.],\n",
       "         [3., 3.]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAfMsaz1Gw5v",
    "outputId": "d0432152-8137-46e7-902a-ec0b779d5471"
   },
   "source": [
    "Perform elementwise multiplication. Use / for division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAfMsaz1Gw5v",
    "outputId": "d0432152-8137-46e7-902a-ec0b779d5471"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2.],\n",
       "         [2., 2.]],\n",
       "\n",
       "        [[2., 2.],\n",
       "         [2., 2.]],\n",
       "\n",
       "        [[2., 2.],\n",
       "         [2., 2.]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aq89FU7OOe7"
   },
   "source": [
    "We can apply the same operations between different tensors of compatible sizes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGhz62wILIfN",
    "outputId": "40f51f08-a80b-41b9-b9a1-e874c8b89e05"
   },
   "source": [
    "Create a 4x3 tensor of 6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGhz62wILIfN",
    "outputId": "40f51f08-a80b-41b9-b9a1-e874c8b89e05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones((4,3)) * 6\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tvDC1OzzPyLV",
    "outputId": "291f0c1f-9a64-4c23-a399-7464c6cbd39e"
   },
   "source": [
    "Create a 1D tensor of 2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tvDC1OzzPyLV",
    "outputId": "291f0c1f-9a64-4c23-a399-7464c6cbd39e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.ones(3) * 2\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUF9noMTP5NI",
    "outputId": "9cd9b5ab-c292-4987-c562-a3f8e4ec8a2f"
   },
   "source": [
    "Divide a by b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUF9noMTP5NI",
    "outputId": "9cd9b5ab-c292-4987-c562-a3f8e4ec8a2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTiVVbukXRct"
   },
   "source": [
    "We can use `tensor.matmul(other_tensor)` for matrix multiplication and `tensor.T` for transpose. Matrix multiplication can also be performed with `@`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bPoC_WcbXCw5",
    "outputId": "332f95f5-11fd-431d-c77a-e4c98dbd6660"
   },
   "source": [
    "Alternative to a.matmul(b)<br/>\n",
    "a @ b.T returns the same result since b is 1D tensor and the 2nd dimension\n",
    "is inferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bPoC_WcbXCw5",
    "outputId": "332f95f5-11fd-431d-c77a-e4c98dbd6660"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36., 36., 36., 36.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2WEoQjVYBQ8",
    "outputId": "0f97c447-5f28-4483-ac82-e1b484663b96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(a.shape)\n",
    "pp.pprint(a.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PibNpxbYYf2"
   },
   "source": [
    "We can take the mean and standard deviation along a certain dimension with the methods `mean(dim)` and `std(dim)`. That is, if we want to get the mean `3x2` matrix in a `4x3x2` matrix, we would set the `dim` to be 0. We can call these methods with no parameter to get the mean and standard deviation for the whole tensor. To use `mean` and `std` our tensor should be a floating point type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a987teCtYg7R",
    "outputId": "0ca3799b-6dec-49ea-c1eb-d6265f390818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Mean: 2.5'\n",
      "'Mean in the 0th dimension: tensor([2.5000, 2.5000])'\n",
      "'Mean in the 1st dimension: tensor([1., 2., 3., 4.])'\n"
     ]
    }
   ],
   "source": [
    "# Create an example tensor\n",
    "m = torch.tensor(\n",
    "    [\n",
    "     [1., 1.],\n",
    "     [2., 2.],\n",
    "     [3., 3.],\n",
    "     [4., 4.]\n",
    "    ]\n",
    ")\n",
    "\n",
    "pp.pprint(\"Mean: {}\".format(m.mean()))\n",
    "pp.pprint(\"Mean in the 0th dimension: {}\".format(m.mean(0)))\n",
    "pp.pprint(\"Mean in the 1st dimension: {}\".format(m.mean(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd77stQ5VQVT"
   },
   "source": [
    "We can concatenate tensors using `torch.cat`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "advfDCOPK9Gw",
    "outputId": "8efcab75-98f0-4562-a58f-fa419604956b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: torch.Size([4, 3])\n",
      "Shape after concatenation in dimension 0: torch.Size([12, 3])\n",
      "Shape after concatenation in dimension 1: torch.Size([4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate in dimension 0 and 1\n",
    "a_cat0 = torch.cat([a, a, a], dim=0)\n",
    "a_cat1 = torch.cat([a, a, a], dim=1)\n",
    "\n",
    "print(\"Initial shape: {}\".format(a.shape))\n",
    "print(\"Shape after concatenation in dimension 0: {}\".format(a_cat0.shape))\n",
    "print(\"Shape after concatenation in dimension 1: {}\".format(a_cat1.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BveswZMOjtff"
   },
   "source": [
    "Most of the operations in `PyTorch` are not in place. However, `PyTorch` offers the in place versions of operations available by adding an underscore (`_`) at the end of the method name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ebr7nn-DaU3B",
    "outputId": "aad366a1-1bbb-4864-8be0-46ef440763b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print our tensor\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mP8-VtoHaKAc",
    "outputId": "94fafdfd-da16-4a94-bdd3-f9935a278ea2"
   },
   "source": [
    "`add()` is not in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mP8-VtoHaKAc",
    "outputId": "94fafdfd-da16-4a94-bdd3-f9935a278ea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mY0ojINbaayp",
    "outputId": "cd396248-e6e4-4d0b-ebf9-5a7411f27882"
   },
   "source": [
    "`add_()` is in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mY0ojINbaayp",
    "outputId": "cd396248-e6e4-4d0b-ebf9-5a7411f27882"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12.],\n",
       "        [12., 12., 12.],\n",
       "        [12., 12., 12.],\n",
       "        [12., 12., 12.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add_(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Re8xiL37eAja"
   },
   "source": [
    "## Autograd\n",
    "`PyTorch` and other machine learning libraries are known for their automatic differantiation feature. That is, given that we have defined the set of operations that need to be performed, the framework itself can figure out how to compute the gradients. We can call the `backward()` method to ask `PyTorch` to calculate the gradiends, which are then stored in the `grad` attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-oEvBJHWfn8H",
    "outputId": "740dc424-2b22-4d2b-ac2a-6d45e06d914b"
   },
   "source": [
    "Create an example tensor.\n",
    " `requires_grad` parameter tells PyTorch to store gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-oEvBJHWfn8H",
    "outputId": "740dc424-2b22-4d2b-ac2a-6d45e06d914b"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "# Print the gradient if it is calculated\n",
    "# Currently None since x is a scalar\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DTJazZXkgthP",
    "outputId": "e3d72745-0206-4c31-e11e-7b7ad833d5b5"
   },
   "source": [
    "$$y = 3x^2$$\n",
    "\n",
    "Calculating the gradient of $y$ with respect to $x$:\n",
    "    \n",
    "$$\\frac{d y}{d x} = \\frac{d 3x^2}{d x} = 6x = 12$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DTJazZXkgthP",
    "outputId": "e3d72745-0206-4c31-e11e-7b7ad833d5b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 3 * x * x\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Hqc2oM3iV6a"
   },
   "source": [
    "Let's run backprop from a different tensor again to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K--Az0Xiic_z",
    "outputId": "21195fa0-8466-4a33-92df-be40e3c33745"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([24.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 3 * x * x\n",
    "z.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhjPkiE6i7ja"
   },
   "source": [
    "We can see that the `x.grad` is updated to be the sum of the gradients calculated so far. When we run backprop in a neural network, we sum up all the gradients for a particular neuron before making an update. This is exactly what is happening here! This is also the reason why we need to run `zero_grad()` in every training iteration (more on this later). Otherwise our gradients would keep building up from one training iteration to the other, which would cause our updates to be wrong. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYLWqKIoaOyd"
   },
   "source": [
    "## Neural Network Module\n",
    "\n",
    "So far we have looked into the tensors, their properties and basic operations on tensors. These are especially useful to get familiar with if we are building the layers of our network from scratch.\n",
    "We will use predefined blocks in the `torch.nn` module of `PyTorch`. We will then put together these blocks to create complex networks. Let's start by importing this module with an alias so that we don't have to type `torch` every time we use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qUmrDpbhV4Tn"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joGvRWjEbak0"
   },
   "source": [
    "### **Linear Layer**\n",
    "We can use `nn.Linear(H_in, H_out)` to create a a linear layer. This will take a matrix of `(N, *, H_in)` dimensions and output a matrix of `(N, *, H_out)`. The `*` denotes that there could be arbitrary number of dimensions in between. The linear layer performs the operation `Ax+b`, where `A` and `b` are initialized randomly. If we don't want the linear layer to learn the bias parameters, we can initialize our layer with `bias=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XfnKI4-a5j9",
    "outputId": "867af230-5f0a-4b0b-c06c-025b1b8b0b0f"
   },
   "outputs": [],
   "source": [
    "# Create the inputs\n",
    "input = torch.ones(2,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XfnKI4-a5j9",
    "outputId": "867af230-5f0a-4b0b-c06c-025b1b8b0b0f"
   },
   "source": [
    "Make a linear layers transforming N,*,H_in dimensinal inputs to N,*,H_out\n",
    "dimensional outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XfnKI4-a5j9",
    "outputId": "867af230-5f0a-4b0b-c06c-025b1b8b0b0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0172, -1.3738],\n",
       "         [ 0.0172, -1.3738],\n",
       "         [ 0.0172, -1.3738]],\n",
       "\n",
       "        [[ 0.0172, -1.3738],\n",
       "         [ 0.0172, -1.3738],\n",
       "         [ 0.0172, -1.3738]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(4, 2) # H_in = 4, H_out = 2\n",
    "linear_output = linear(input)\n",
    "linear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch keeps track of the variables present in an expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_9XKtAFYpdI",
    "outputId": "df248f31-e5ca-4857-88c2-c0bbc61a40be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2843, -0.3597, -0.2036, -0.1495],\n",
       "         [-0.4745, -0.4165, -0.4865, -0.0082]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4456, 0.0119], requires_grad=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(linear.parameters()) # Ax + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Linear in module torch.nn.modules.linear:\n",
      "\n",
      "class Linear(torch.nn.modules.module.Module)\n",
      " |  Linear(in_features: int, out_features: int, bias: bool = True) -> None\n",
      " |  \n",
      " |  Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
      " |  \n",
      " |  This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      " |  \n",
      " |  Args:\n",
      " |      in_features: size of each input sample\n",
      " |      out_features: size of each output sample\n",
      " |      bias: If set to ``False``, the layer will not learn an additive bias.\n",
      " |          Default: ``True``\n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(N, *, H_{in})` where :math:`*` means any number of\n",
      " |        additional dimensions and :math:`H_{in} = \\text{in\\_features}`\n",
      " |      - Output: :math:`(N, *, H_{out})` where all but the last dimension\n",
      " |        are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight: the learnable weights of the module of shape\n",
      " |          :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
      " |          initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      " |          :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      " |      bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
      " |              If :attr:`bias` is ``True``, the values are initialized from\n",
      " |              :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      " |              :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> m = nn.Linear(20, 30)\n",
      " |      >>> input = torch.randn(128, 20)\n",
      " |      >>> output = m(input)\n",
      " |      >>> print(output.size())\n",
      " |      torch.Size([128, 30])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Linear\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, in_features: int, out_features: int, bias: bool = True) -> None\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  forward(self, input: torch.Tensor) -> torch.Tensor\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  reset_parameters(self) -> None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'in_features': <class 'int'>, 'out_features': <clas...\n",
      " |  \n",
      " |  __constants__ = ['in_features', 'out_features']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name: str, module: Union[ForwardRef('Module'), NoneType]) -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Dict[str, torch.Tensor], strict: bool = True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Union[Set[ForwardRef('Module')], NoneType] = None, prefix: str = '')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |      \n",
      " |          The current implementation will not have the presented behavior\n",
      " |          for complex :class:`Module` that perform many operations.\n",
      " |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n",
      " |          contain the gradients for a subset of the inputs and outputs.\n",
      " |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n",
      " |          directly on a specific input or output to get the required gradients.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Union[torch.Tensor, NoneType], persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Union[torch.nn.parameter.Parameter, NoneType]) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point desired :attr:`dtype` s. In addition, this method will\n",
      " |      only cast the floating point parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = False) -> None\n",
      " |      Sets gradients of all model parameters to zero. See similar function\n",
      " |      under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAXCCu9keUlW"
   },
   "source": [
    "### **Other Module Layers**\n",
    "There are several other preconfigured layers in the `nn` module. Some commonly used examples are `nn.Conv2d`, `nn.ConvTranspose2d`, `nn.BatchNorm1d`, `nn.BatchNorm2d`, `nn.Upsample` and `nn.MaxPool2d` among many others.\n",
    "\n",
    "For now, the only important thing to remember is that we can treat each of these layers as plug and play components: we will be providing the required dimensions and `PyTorch` will take care of setting them up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yslDOK66fYWn"
   },
   "source": [
    "### **Activation Function Layer**\n",
    "We can also use the `nn` module to apply activations functions to our tensors. Activation functions are used to add non-linearity to our network. Some examples of activations functions are `nn.ReLU()`, `nn.Sigmoid()` and `nn.LeakyReLU()`. Activation functions operate on each element seperately, so the shape of the tensors we get as an output are the same as the ones we pass in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9v5FjQtd4Ck",
    "outputId": "966538af-4eac-475b-dd30-9174efd7ed3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5043, 0.2020],\n",
       "         [0.5043, 0.2020],\n",
       "         [0.5043, 0.2020]],\n",
       "\n",
       "        [[0.5043, 0.2020],\n",
       "         [0.5043, 0.2020],\n",
       "         [0.5043, 0.2020]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "output = sigmoid(linear_output)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"252pt\" height=\"448pt\"\n",
       " viewBox=\"0.00 0.00 252.00 448.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 444)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-444 248,-444 248,4 -4,4\"/>\n",
       "<!-- 139665149477504 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139665149477504</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"166,-31 89,-31 89,0 166,0 166,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (2, 3, 2)</text>\n",
       "</g>\n",
       "<!-- 139662920759472 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139662920759472</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"181,-86 74,-86 74,-67 181,-67 181,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SigmoidBackward</text>\n",
       "</g>\n",
       "<!-- 139662920759472&#45;&gt;139665149477504 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>139662920759472&#45;&gt;139665149477504</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127.5,-66.79C127.5,-60.07 127.5,-50.4 127.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"131,-41.19 127.5,-31.19 124,-41.19 131,-41.19\"/>\n",
       "</g>\n",
       "<!-- 139662920759616 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139662920759616</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"172,-141 83,-141 83,-122 172,-122 172,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 139662920759616&#45;&gt;139662920759472 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139662920759616&#45;&gt;139662920759472</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127.5,-121.75C127.5,-114.8 127.5,-104.85 127.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"131,-96.09 127.5,-86.09 124,-96.09 131,-96.09\"/>\n",
       "</g>\n",
       "<!-- 139662920759424 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139662920759424</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"125,-196 0,-196 0,-177 125,-177 125,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">UnsafeViewBackward</text>\n",
       "</g>\n",
       "<!-- 139662920759424&#45;&gt;139662920759616 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139662920759424&#45;&gt;139662920759616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M72.94,-176.98C82.65,-169.07 97.32,-157.11 109,-147.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"111.33,-150.2 116.87,-141.17 106.9,-144.78 111.33,-150.2\"/>\n",
       "</g>\n",
       "<!-- 139662920759712 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139662920759712</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-257 24,-257 24,-238 101,-238 101,-257\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.5\" y=\"-245\" font-family=\"monospace\" font-size=\"10.00\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 139662920759712&#45;&gt;139662920759424 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139662920759712&#45;&gt;139662920759424</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.5,-237.79C62.5,-229.6 62.5,-217.06 62.5,-206.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66,-206.24 62.5,-196.24 59,-206.24 66,-206.24\"/>\n",
       "</g>\n",
       "<!-- 139662920759808 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>139662920759808</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"98,-318 27,-318 27,-299 98,-299 98,-318\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.5\" y=\"-306\" font-family=\"monospace\" font-size=\"10.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139662920759808&#45;&gt;139662920759712 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139662920759808&#45;&gt;139662920759712</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.5,-298.79C62.5,-290.6 62.5,-278.06 62.5,-267.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66,-267.24 62.5,-257.24 59,-267.24 66,-267.24\"/>\n",
       "</g>\n",
       "<!-- 139662920759904 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>139662920759904</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"113,-373 12,-373 12,-354 113,-354 113,-373\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.5\" y=\"-361\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139662920759904&#45;&gt;139662920759808 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>139662920759904&#45;&gt;139662920759808</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.5,-353.75C62.5,-346.8 62.5,-336.85 62.5,-328.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66,-328.09 62.5,-318.09 59,-328.09 66,-328.09\"/>\n",
       "</g>\n",
       "<!-- 139662922183552 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>139662922183552</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"92,-440 33,-440 33,-409 92,-409 92,-440\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.5\" y=\"-416\" font-family=\"monospace\" font-size=\"10.00\"> (2, 4)</text>\n",
       "</g>\n",
       "<!-- 139662922183552&#45;&gt;139662920759904 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>139662922183552&#45;&gt;139662920759904</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.5,-408.92C62.5,-401.22 62.5,-391.69 62.5,-383.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66,-383.25 62.5,-373.25 59,-383.25 66,-383.25\"/>\n",
       "</g>\n",
       "<!-- 139662920759232 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>139662920759232</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"244,-196 143,-196 143,-177 244,-177 244,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"193.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139662920759232&#45;&gt;139662920759616 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>139662920759232&#45;&gt;139662920759616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M182.9,-176.98C173.04,-169.07 158.15,-157.11 146.28,-147.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"148.29,-144.7 138.3,-141.17 143.9,-150.16 148.29,-144.7\"/>\n",
       "</g>\n",
       "<!-- 139662922183744 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>139662922183744</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"220.5,-263 166.5,-263 166.5,-232 220.5,-232 220.5,-263\"/>\n",
       "<text text-anchor=\"middle\" x=\"193.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> (2)</text>\n",
       "</g>\n",
       "<!-- 139662922183744&#45;&gt;139662920759232 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>139662922183744&#45;&gt;139662920759232</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M193.5,-231.92C193.5,-224.22 193.5,-214.69 193.5,-206.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"197,-206.25 193.5,-196.25 190,-206.25 197,-206.25\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f05cec7b820>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "make_dot(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiYTthJwhEYT"
   },
   "source": [
    "### **Putting the Layers Together**\n",
    "So far we have seen that we can create layers and pass the output of one as the input of the next. Instead of creating intermediate tensors and passing them around, we can use `nn.Sequentual`, which does exactly that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xtJeOqLxhBLY",
    "outputId": "b2370e4a-47bc-47f2-e784-d7fcd3ce57b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6612, 0.8247],\n",
       "         [0.6612, 0.8247],\n",
       "         [0.6612, 0.8247]],\n",
       "\n",
       "        [[0.6612, 0.8247],\n",
       "         [0.6612, 0.8247],\n",
       "         [0.6612, 0.8247]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "input = torch.ones(2,3,4)\n",
    "output = block(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkJ81p3GUVPM"
   },
   "source": [
    "### Custom Modules\n",
    "\n",
    "Instead of using the predefined modules, we can also build our own by extending the `nn.Module` class. For example, we can build a the `nn.Linear` (which also extends `nn.Module`) on our own using the tensor introduced earlier! We can also build new, more complex modules, such as a custom neural network. You will be practicing these in the later assignment.\n",
    "\n",
    "To create a custom module, the first thing we have to do is to extend the `nn.Module`. We can then initialize our parameters in the `__init__` function, starting with a call to the `__init__` function of the super class.\n",
    "\n",
    "All the class attributes we define which are `nn` module objects are treated as parameters, which can be learned during the training. Tensors are not parameters, but they can be turned into parameters if they are wrapped in `nn.Parameter` class.\n",
    "\n",
    "All classes extending `nn.Module` are also expected to implement a `forward(x)` function, where `x` is a tensor. This is the function that is called when a parameter is passed to our module, such as in `model(x)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "J2P7eZiMj32_"
   },
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    # Call to the __init__ function of the super class\n",
    "    super().__init__()\n",
    "\n",
    "    # Bookkeeping: Saving the initialization parameters\n",
    "    self.input_size = input_size \n",
    "    self.hidden_size = hidden_size \n",
    "\n",
    "    # Defining of our model\n",
    "    self.model = nn.Sequential(\n",
    "        nn.Linear(self.input_size, self.hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(self.hidden_size, self.input_size),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    output = self.model(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2DrfLiBVjNT"
   },
   "source": [
    "Here is an alternative way to define the same class. You can see that we can replace `nn.Sequential` by defining the individual layers in the `__init__` method and connecting them in the `forward` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "9-lqhsqwViIk"
   },
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    # Call to the __init__ function of the super class\n",
    "    super().__init__()\n",
    "\n",
    "    # Bookkeeping: Saving the initialization parameters\n",
    "    self.input_size = input_size \n",
    "    self.hidden_size = hidden_size \n",
    "\n",
    "    # Defining of our layers\n",
    "    self.linear = nn.Linear(self.input_size, self.hidden_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.linear2 = nn.Linear(self.hidden_size, self.input_size)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "  def forward(self, x):\n",
    "    linear = self.linear(x)\n",
    "    relu = self.relu(linear)\n",
    "    linear2 = self.linear2(relu)\n",
    "    output = self.sigmoid(linear2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQelcFo5bXgU"
   },
   "source": [
    "Now that we have defined our class, we can instantiate it and see what it does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXi0T0FZbV0y",
    "outputId": "23547003-cfef-4a6d-e3f4-5fdb7a5cdd97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6139, 0.4648, 0.6163, 0.5344, 0.3689],\n",
       "        [0.5506, 0.4831, 0.5785, 0.5397, 0.3397]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a sample input\n",
    "input = torch.randn(2, 5)\n",
    "\n",
    "# Create our model\n",
    "mlp = MultilayerPerceptron(5, 3)\n",
    "\n",
    "# Pass our input through our model\n",
    "mlp(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCCbjc-Fb2-B"
   },
   "source": [
    "We can inspect the parameters of our model with `named_parameters()` and `parameters()` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d23soYIb2WZ",
    "outputId": "3bf4243d-2f85-4593-8989-680b322aca13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('linear.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2388,  0.4095, -0.1509, -0.1585, -0.4327],\n",
       "          [-0.2561,  0.1117, -0.0590, -0.3246,  0.0105],\n",
       "          [-0.3055, -0.3794, -0.2463, -0.3914, -0.2848]], requires_grad=True)),\n",
       " ('linear.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.4470, 0.0845, 0.1378], requires_grad=True)),\n",
       " ('linear2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.5385, -0.3792, -0.1922],\n",
       "          [ 0.0903, -0.5080, -0.2488],\n",
       "          [-0.3456,  0.0016, -0.2148],\n",
       "          [-0.0400, -0.3912, -0.3963],\n",
       "          [-0.3368, -0.1976, -0.4557]], requires_grad=True)),\n",
       " ('linear2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.4841, -0.1146,  0.4968,  0.1799, -0.4889], requires_grad=True))]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mlp.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5JegycOdMFy"
   },
   "source": [
    "## Optimization\n",
    "We have shown how gradients are calculated with the `backward()` function. Having the gradients isn't enought for our models to learn. We also need to know how to update the parameters of our models. This is where the optomozers comes in.\n",
    "\n",
    "`torch.optim` module contains several optimizers that we can use. Some popular examples are `optim.SGD` and `optim.Adam`. When initializing optimizers, we pass our model parameters, which can be accessed with `model.parameters()`, telling the optimizers which values it will be optimizing. Optimizers also has a learning rate (`lr`) parameter, which determines how big of an update will be made in every step. Different optimizers have different hyperparameters as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "W0F-TvV0kk-I"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgak6o5dlQWF"
   },
   "source": [
    "After we have our optimization function, we can define a `loss` that we want to optimize for. We can either define the loss ourselves, or use one of the predefined loss function in `PyTorch`, such as `nn.BCELoss()`, Binary Cross Entropy.\n",
    "\n",
    "Let's put everything together now! We will start by creating some dummy data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGYFiaT_vXBn",
    "outputId": "48bd9b70-f225-4c20-fad7-5f7a6fa4ed9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.6354,  1.6547,  1.5760,  0.6391,  0.9394],\n",
       "        [ 1.0733,  1.8187,  2.4805,  2.0331,  0.3133],\n",
       "        [ 1.6368,  1.2176,  0.9533, -0.4335,  0.4335],\n",
       "        [ 0.5747,  0.7896,  0.2672,  1.1043,  2.0414],\n",
       "        [ 0.6003, -1.2933,  1.4976,  0.5743,  0.5825],\n",
       "        [-0.1955,  1.8123,  0.6937,  0.6698,  0.0192],\n",
       "        [ 1.1947, -0.6535,  0.2692,  1.1748,  0.4774],\n",
       "        [ 1.7165,  2.5335, -0.4510,  0.2139,  0.0437],\n",
       "        [-0.2476,  0.2501,  1.7099, -0.5326,  0.2749],\n",
       "        [ 1.4664,  1.6667,  0.9561,  1.2368,  0.2939]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the y data\n",
    "y = torch.ones(10, 5)\n",
    "\n",
    "# Add some noise to our goal y to generate our x\n",
    "# We want out model to predict our original data, despite the noise\n",
    "x = y + torch.randn_like(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEsiOdpWvfLj"
   },
   "source": [
    "Now, we can define our model, optimizer and the loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oA2XsdsbN8p",
    "outputId": "b4cd8c6c-d2e9-4594-f238-234d61e027d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-0854ac2f7ca7>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_pred = mlp(torch.tensor(x_train))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7258154153823853"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "mlp = MultilayerPerceptron(5, 3)\n",
    "\n",
    "# Define the optimizer\n",
    "mlp_adam = optim.Adam(mlp.parameters(), lr=1e-1)\n",
    "\n",
    "# Define loss using a predefined loss function\n",
    "mlp_loss_function = nn.BCELoss()\n",
    "\n",
    "# Calculate how our model is doing now\n",
    "y_pred = mlp(torch.tensor(x_train))\n",
    "mlp_loss_function(y_pred, y_train).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"337pt\" height=\"472pt\"\n",
       " viewBox=\"0.00 0.00 337.00 472.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 468)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-468 333,-468 333,4 -4,4\"/>\n",
       "<!-- 139662848788608 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139662848788608</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"199,-31 134,-31 134,0 199,0 199,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (10, 5)</text>\n",
       "</g>\n",
       "<!-- 139662848728704 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139662848728704</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"220,-86 113,-86 113,-67 220,-67 220,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SigmoidBackward</text>\n",
       "</g>\n",
       "<!-- 139662848728704&#45;&gt;139662848788608 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>139662848728704&#45;&gt;139662848788608</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.5,-66.79C166.5,-60.07 166.5,-50.4 166.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170,-41.19 166.5,-31.19 163,-41.19 170,-41.19\"/>\n",
       "</g>\n",
       "<!-- 139662848728992 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139662848728992</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-141 119,-141 119,-122 214,-122 214,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 139662848728992&#45;&gt;139662848728704 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139662848728992&#45;&gt;139662848728704</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.5,-121.75C166.5,-114.8 166.5,-104.85 166.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170,-96.09 166.5,-86.09 163,-96.09 170,-96.09\"/>\n",
       "</g>\n",
       "<!-- 139662848726880 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139662848726880</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139662848726880&#45;&gt;139662848728992 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139662848726880&#45;&gt;139662848728992</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M69.14,-176.98C87.8,-168.46 116.75,-155.23 138.24,-145.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"139.88,-148.51 147.52,-141.17 136.97,-142.14 139.88,-148.51\"/>\n",
       "</g>\n",
       "<!-- 139662848853888 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139662848853888</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-263 23.5,-263 23.5,-232 77.5,-232 77.5,-263\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> (5)</text>\n",
       "</g>\n",
       "<!-- 139662848853888&#45;&gt;139662848726880 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139662848853888&#45;&gt;139662848726880</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.92C50.5,-224.22 50.5,-214.69 50.5,-206.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.25 50.5,-196.25 47,-206.25 54,-206.25\"/>\n",
       "</g>\n",
       "<!-- 139662848727648 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>139662848727648</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-196 119,-196 119,-177 214,-177 214,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 139662848727648&#45;&gt;139662848728992 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139662848727648&#45;&gt;139662848728992</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.5,-176.75C166.5,-169.8 166.5,-159.85 166.5,-151.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170,-151.09 166.5,-141.09 163,-151.09 170,-151.09\"/>\n",
       "</g>\n",
       "<!-- 139662848726832 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>139662848726832</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"210,-257 115,-257 115,-238 210,-238 210,-257\"/>\n",
       "<text text-anchor=\"middle\" x=\"162.5\" y=\"-245\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 139662848726832&#45;&gt;139662848727648 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>139662848726832&#45;&gt;139662848727648</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.09,-237.79C163.65,-229.6 164.5,-217.06 165.21,-206.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"168.72,-206.46 165.91,-196.24 161.74,-205.98 168.72,-206.46\"/>\n",
       "</g>\n",
       "<!-- 139662848728848 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>139662848728848</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"126,-324 25,-324 25,-305 126,-305 126,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"75.5\" y=\"-312\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139662848728848&#45;&gt;139662848726832 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>139662848728848&#45;&gt;139662848726832</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M87.23,-304.73C101.45,-294.11 125.63,-276.05 142.74,-263.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"145.04,-265.92 150.95,-257.13 140.85,-260.31 145.04,-265.92\"/>\n",
       "</g>\n",
       "<!-- 139662848852416 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>139662848852416</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"102.5,-397 48.5,-397 48.5,-366 102.5,-366 102.5,-397\"/>\n",
       "<text text-anchor=\"middle\" x=\"75.5\" y=\"-373\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n",
       "</g>\n",
       "<!-- 139662848852416&#45;&gt;139662848728848 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>139662848852416&#45;&gt;139662848728848</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M75.5,-365.75C75.5,-356.39 75.5,-344.19 75.5,-334.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79,-334.02 75.5,-324.02 72,-334.02 79,-334.02\"/>\n",
       "</g>\n",
       "<!-- 139662848727696 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>139662848727696</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"215,-324 144,-324 144,-305 215,-305 215,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-312\" font-family=\"monospace\" font-size=\"10.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139662848727696&#45;&gt;139662848726832 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>139662848727696&#45;&gt;139662848726832</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M177.21,-304.73C174.68,-295.09 170.56,-279.3 167.31,-266.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170.67,-265.92 164.76,-257.13 163.9,-267.69 170.67,-265.92\"/>\n",
       "</g>\n",
       "<!-- 139662848728320 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>139662848728320</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"230,-391 129,-391 129,-372 230,-372 230,-391\"/>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-379\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139662848728320&#45;&gt;139662848727696 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>139662848728320&#45;&gt;139662848727696</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M179.5,-371.73C179.5,-362.18 179.5,-346.62 179.5,-334.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183,-334.13 179.5,-324.13 176,-334.13 183,-334.13\"/>\n",
       "</g>\n",
       "<!-- 139662848852160 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>139662848852160</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"209,-464 150,-464 150,-433 209,-433 209,-464\"/>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-440\" font-family=\"monospace\" font-size=\"10.00\"> (3, 5)</text>\n",
       "</g>\n",
       "<!-- 139662848852160&#45;&gt;139662848728320 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>139662848852160&#45;&gt;139662848728320</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M179.5,-432.75C179.5,-423.39 179.5,-411.19 179.5,-401.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183,-401.02 179.5,-391.02 176,-401.02 183,-401.02\"/>\n",
       "</g>\n",
       "<!-- 139662848727072 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>139662848727072</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"310,-196 239,-196 239,-177 310,-177 310,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"274.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139662848727072&#45;&gt;139662848728992 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>139662848727072&#45;&gt;139662848728992</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M257.15,-176.98C239.93,-168.54 213.3,-155.47 193.35,-145.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"194.69,-142.43 184.17,-141.17 191.6,-148.72 194.69,-142.43\"/>\n",
       "</g>\n",
       "<!-- 139662848727888 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>139662848727888</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"329,-257 228,-257 228,-238 329,-238 329,-257\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.5\" y=\"-245\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139662848727888&#45;&gt;139662848727072 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>139662848727888&#45;&gt;139662848727072</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M277.91,-237.79C277.35,-229.6 276.5,-217.06 275.79,-206.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"279.26,-205.98 275.09,-196.24 272.28,-206.46 279.26,-205.98\"/>\n",
       "</g>\n",
       "<!-- 139662848853504 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>139662848853504</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"308,-330 249,-330 249,-299 308,-299 308,-330\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.5\" y=\"-306\" font-family=\"monospace\" font-size=\"10.00\"> (5, 3)</text>\n",
       "</g>\n",
       "<!-- 139662848853504&#45;&gt;139662848727888 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>139662848853504&#45;&gt;139662848727888</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278.5,-298.75C278.5,-289.39 278.5,-277.19 278.5,-267.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282,-267.02 278.5,-257.02 275,-267.02 282,-267.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f05ca7c96a0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"337pt\" height=\"527pt\"\n",
       " viewBox=\"0.00 0.00 337.00 527.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 523)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-523 333,-523 333,4 -4,4\"/>\n",
       "<!-- 139662848913856 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139662848913856</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"193.5,-31 139.5,-31 139.5,0 193.5,0 193.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 139662849297520 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139662849297520</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"253,-86 80,-86 80,-67 253,-67 253,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">BinaryCrossEntropyBackward</text>\n",
       "</g>\n",
       "<!-- 139662849297520&#45;&gt;139662848913856 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>139662849297520&#45;&gt;139662848913856</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.5,-66.79C166.5,-60.07 166.5,-50.4 166.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170,-41.19 166.5,-31.19 163,-41.19 170,-41.19\"/>\n",
       "</g>\n",
       "<!-- 139662848728704 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139662848728704</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"220,-141 113,-141 113,-122 220,-122 220,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">SigmoidBackward</text>\n",
       "</g>\n",
       "<!-- 139662848728704&#45;&gt;139662849297520 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139662848728704&#45;&gt;139662849297520</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.5,-121.75C166.5,-114.8 166.5,-104.85 166.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170,-96.09 166.5,-86.09 163,-96.09 170,-96.09\"/>\n",
       "</g>\n",
       "<!-- 139662848728992 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139662848728992</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-196 119,-196 119,-177 214,-177 214,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 139662848728992&#45;&gt;139662848728704 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139662848728992&#45;&gt;139662848728704</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.5,-176.75C166.5,-169.8 166.5,-159.85 166.5,-151.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170,-151.09 166.5,-141.09 163,-151.09 170,-151.09\"/>\n",
       "</g>\n",
       "<!-- 139662848726880 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139662848726880</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-251 0,-251 0,-232 101,-232 101,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139662848726880&#45;&gt;139662848728992 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139662848726880&#45;&gt;139662848728992</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M69.14,-231.98C87.8,-223.46 116.75,-210.23 138.24,-200.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"139.88,-203.51 147.52,-196.17 136.97,-197.14 139.88,-203.51\"/>\n",
       "</g>\n",
       "<!-- 139662848853888 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>139662848853888</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-318 23.5,-318 23.5,-287 77.5,-287 77.5,-318\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> (5)</text>\n",
       "</g>\n",
       "<!-- 139662848853888&#45;&gt;139662848726880 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139662848853888&#45;&gt;139662848726880</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.92C50.5,-279.22 50.5,-269.69 50.5,-261.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-261.25 50.5,-251.25 47,-261.25 54,-261.25\"/>\n",
       "</g>\n",
       "<!-- 139662848727648 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>139662848727648</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-251 119,-251 119,-232 214,-232 214,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 139662848727648&#45;&gt;139662848728992 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>139662848727648&#45;&gt;139662848728992</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.5,-231.75C166.5,-224.8 166.5,-214.85 166.5,-206.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170,-206.09 166.5,-196.09 163,-206.09 170,-206.09\"/>\n",
       "</g>\n",
       "<!-- 139662848726832 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>139662848726832</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"210,-312 115,-312 115,-293 210,-293 210,-312\"/>\n",
       "<text text-anchor=\"middle\" x=\"162.5\" y=\"-300\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 139662848726832&#45;&gt;139662848727648 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>139662848726832&#45;&gt;139662848727648</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.09,-292.79C163.65,-284.6 164.5,-272.06 165.21,-261.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"168.72,-261.46 165.91,-251.24 161.74,-260.98 168.72,-261.46\"/>\n",
       "</g>\n",
       "<!-- 139662848728848 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>139662848728848</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"126,-379 25,-379 25,-360 126,-360 126,-379\"/>\n",
       "<text text-anchor=\"middle\" x=\"75.5\" y=\"-367\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139662848728848&#45;&gt;139662848726832 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>139662848728848&#45;&gt;139662848726832</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M87.23,-359.73C101.45,-349.11 125.63,-331.05 142.74,-318.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"145.04,-320.92 150.95,-312.13 140.85,-315.31 145.04,-320.92\"/>\n",
       "</g>\n",
       "<!-- 139662848852416 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>139662848852416</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"102.5,-452 48.5,-452 48.5,-421 102.5,-421 102.5,-452\"/>\n",
       "<text text-anchor=\"middle\" x=\"75.5\" y=\"-428\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n",
       "</g>\n",
       "<!-- 139662848852416&#45;&gt;139662848728848 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>139662848852416&#45;&gt;139662848728848</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M75.5,-420.75C75.5,-411.39 75.5,-399.19 75.5,-389.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79,-389.02 75.5,-379.02 72,-389.02 79,-389.02\"/>\n",
       "</g>\n",
       "<!-- 139662848727696 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>139662848727696</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"215,-379 144,-379 144,-360 215,-360 215,-379\"/>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-367\" font-family=\"monospace\" font-size=\"10.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139662848727696&#45;&gt;139662848726832 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>139662848727696&#45;&gt;139662848726832</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M177.21,-359.73C174.68,-350.09 170.56,-334.3 167.31,-321.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170.67,-320.92 164.76,-312.13 163.9,-322.69 170.67,-320.92\"/>\n",
       "</g>\n",
       "<!-- 139662848728320 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>139662848728320</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"230,-446 129,-446 129,-427 230,-427 230,-446\"/>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-434\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139662848728320&#45;&gt;139662848727696 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>139662848728320&#45;&gt;139662848727696</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M179.5,-426.73C179.5,-417.18 179.5,-401.62 179.5,-389.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183,-389.13 179.5,-379.13 176,-389.13 183,-389.13\"/>\n",
       "</g>\n",
       "<!-- 139662848852160 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>139662848852160</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"209,-519 150,-519 150,-488 209,-488 209,-519\"/>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-495\" font-family=\"monospace\" font-size=\"10.00\"> (3, 5)</text>\n",
       "</g>\n",
       "<!-- 139662848852160&#45;&gt;139662848728320 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>139662848852160&#45;&gt;139662848728320</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M179.5,-487.75C179.5,-478.39 179.5,-466.19 179.5,-456.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183,-456.02 179.5,-446.02 176,-456.02 183,-456.02\"/>\n",
       "</g>\n",
       "<!-- 139662848727072 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>139662848727072</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"310,-251 239,-251 239,-232 310,-232 310,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"274.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139662848727072&#45;&gt;139662848728992 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>139662848727072&#45;&gt;139662848728992</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M257.15,-231.98C239.93,-223.54 213.3,-210.47 193.35,-200.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"194.69,-197.43 184.17,-196.17 191.6,-203.72 194.69,-197.43\"/>\n",
       "</g>\n",
       "<!-- 139662848727888 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>139662848727888</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"329,-312 228,-312 228,-293 329,-293 329,-312\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.5\" y=\"-300\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139662848727888&#45;&gt;139662848727072 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>139662848727888&#45;&gt;139662848727072</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M277.91,-292.79C277.35,-284.6 276.5,-272.06 275.79,-261.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"279.26,-260.98 275.09,-251.24 272.28,-261.46 279.26,-260.98\"/>\n",
       "</g>\n",
       "<!-- 139662848853504 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>139662848853504</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"308,-385 249,-385 249,-354 308,-354 308,-385\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.5\" y=\"-361\" font-family=\"monospace\" font-size=\"10.00\"> (5, 3)</text>\n",
       "</g>\n",
       "<!-- 139662848853504&#45;&gt;139662848727888 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>139662848853504&#45;&gt;139662848727888</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278.5,-353.75C278.5,-344.39 278.5,-332.19 278.5,-322.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282,-322.02 278.5,-312.02 275,-322.02 282,-322.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f05ca854ee0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(mlp_loss_function(y_pred, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtxU7Y8ZufSR"
   },
   "source": [
    "Let's see if we can have our model achieve a smaller loss. Now that we have everything we need, we can setup our training loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogl6-Ctmuek6",
    "outputId": "b22f36a0-c702-4c89-e5d4-27c60d27c0ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: traing loss: 0.7258154153823853\n",
      "Epoch 1: traing loss: 0.6332100033760071\n",
      "Epoch 2: traing loss: 0.5517269968986511\n",
      "Epoch 3: traing loss: 0.4693896472454071\n",
      "Epoch 4: traing loss: 0.38536524772644043\n",
      "Epoch 5: traing loss: 0.30662333965301514\n",
      "Epoch 6: traing loss: 0.23861147463321686\n",
      "Epoch 7: traing loss: 0.18278011679649353\n",
      "Epoch 8: traing loss: 0.13916952908039093\n",
      "Epoch 9: traing loss: 0.1066889837384224\n"
     ]
    }
   ],
   "source": [
    "# Set the number of epoch, which determines the number of training iterations\n",
    "n_epoch = 10 \n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "  # Set the gradients to 0\n",
    "  mlp_adam.zero_grad()\n",
    "\n",
    "  # Get the model predictions\n",
    "  y_pred = mlp(x_train)\n",
    "\n",
    "  # Get the loss\n",
    "  loss = mlp_loss_function(y_pred, y_train)\n",
    "\n",
    "  # Print stats\n",
    "  print(f\"Epoch {epoch}: traing loss: {loss}\")\n",
    "\n",
    "  # Compute the gradients\n",
    "  loss.backward()\n",
    "\n",
    "  # Take a step to optimize the weights\n",
    "  mlp_adam.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrMJ8AmqeCY-",
    "outputId": "73815ecf-9630-4273-9cbb-516258bafe10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.8147,  0.8913,  0.7634,  0.9919,  1.0139],\n",
       "         [-0.4873, -0.3259, -0.7296, -0.5109, -0.0876],\n",
       "         [-0.2203, -0.1273,  0.4282, -1.1687,  0.1692]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3495, -0.5294, -0.0841], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0091, -0.0204,  0.2223],\n",
       "         [ 1.2082, -0.0107,  0.6367],\n",
       "         [ 1.2021,  0.1516,  0.6472],\n",
       "         [ 0.8843,  0.2822,  0.4044],\n",
       "         [ 0.4509, -0.0479,  0.3914]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.4580, 0.6371, 0.5310, 1.0574, 1.1056], requires_grad=True)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mlp.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nXApd82wlsF"
   },
   "source": [
    "You can see that our loss is decreasing. Let's check the predictions of our model now and see if they are close to our original `y`, which was all `1s`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRqE7P9EtvuS",
    "outputId": "d4c76a74-0568-43a9-da28-f25340b87e7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9977, 0.9979, 0.9976, 0.9939, 0.9595],\n",
       "         [0.9928, 0.9918, 0.9906, 0.9836, 0.9343],\n",
       "         [0.9996, 0.9998, 0.9998, 0.9988, 0.9847],\n",
       "         [0.9999, 0.9999, 0.9999, 0.9995, 0.9884],\n",
       "         [0.8484, 0.8013, 0.7863, 0.8237, 0.8279]], grad_fn=<SliceBackward>),\n",
       " tensor([[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how our model performs on the training data\n",
    "y_pred = mlp(x_train)\n",
    "y_pred[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJng31_Pi2R6",
    "outputId": "c69fbad9-28f2-4529-c171-1849ed811a56"
   },
   "source": [
    "Create test data and check how our model performs on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJng31_Pi2R6",
    "outputId": "c69fbad9-28f2-4529-c171-1849ed811a56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9978, 0.9980, 0.9977, 0.9942, 0.9604],\n",
       "         [0.9986, 0.9988, 0.9987, 0.9961, 0.9674],\n",
       "         [0.9946, 0.9952, 0.9946, 0.9886, 0.9495],\n",
       "         [0.9997, 0.9998, 0.9998, 0.9990, 0.9838],\n",
       "         [0.9999, 0.9999, 0.9999, 0.9995, 0.9880]], grad_fn=<SliceBackward>),\n",
       " tensor([], size=(0, 5)))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = y + torch.randn_like(y)\n",
    "y_pred = mlp(x_val)\n",
    "y_pred[:5], y_val[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WNk6oIZw2xo"
   },
   "source": [
    "Great! Looks like our model almost perfectly learned to filter out the noise from the `x` that we passed in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8rUNk_1xG1v"
   },
   "source": [
    "## Demo: Word Window Classification\n",
    "\n",
    "Until this part of the notebook, we have learned the fundamentals of PyTorch and built a basic network solving a toy task. Now we will attempt to solve an example NLP task. Here are the things we will learn:\n",
    "\n",
    "1. Data: Creating a Dataset of Batched Tensors\n",
    "2. Modeling\n",
    "3. Training\n",
    "4. Prediction\n",
    "\n",
    "In this section, our goal will be to train a model that will find the words in a sentence corresponding to a `LOCATION`, which will be always of span `1` (meaning that `San Fransisco` won't be recognized as a `LOCATION`). Our task is called `Word Window Classification` for a reason. Instead of letting our model to only take a look at one word in each forward pass, we would like it to be able to consider the context of the word in question. That is, for each word, we want our model to be aware of the surrounding words. Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_amzuUx8BJXI"
   },
   "source": [
    "### Data\n",
    "\n",
    "The very first task of any machine learning project is to set up our training set. Usually, there will be a training corpus we will be utilizing. In NLP tasks, the corpus would generally be a `.txt` or `.csv` file where each row corresponds to a sentence or a tabular datapoint. In our toy task, we will assume that we have already read our data and the corresponding labels into a `Python` list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDiI1PLMw10z"
   },
   "source": [
    "Our raw data, which consists of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "mDiI1PLMw10z"
   },
   "outputs": [],
   "source": [
    "corpus = [\n",
    "          \"We always come to Paris\",\n",
    "          \"The professor is from Australia\",\n",
    "          \"I live in Stanford\",\n",
    "          \"He comes from Taiwan\",\n",
    "          \"The capital of Turkey is Ankara\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t33Uke9AE22s"
   },
   "source": [
    "#### Preprocessing\n",
    "\n",
    "To make it easier for our models to learn, we usually apply a few preprocessing steps to our data. This is especially important when dealing with text data. Here are some examples of text preprocessing:\n",
    "* **Tokenization**: Tokenizing the sentences into words.\n",
    "* **Lowercasing**: Changing all the letters to be lowercase.\n",
    "* **Noise removal:** Removing special characters (such as punctuations). \n",
    "* **Stop words removal**: Removing commonly used words.\n",
    "\n",
    "Which preprocessing steps are necessary is determined by the task at hand. For example, although it is useful to remove special characters in some tasks, for others they may be important (for example, if we are dealing with multiple languages). For our task, we will lowercase our words and tokenize. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTGn8ANTzZXT",
    "outputId": "5ac3bc25-e5dd-4005-aa36-90836345fb15"
   },
   "source": [
    "The preprocessing function we will use to generate our training examples.\n",
    "Our function is a simple one, we lowercase the letters\n",
    "and then tokenize the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTGn8ANTzZXT",
    "outputId": "5ac3bc25-e5dd-4005-aa36-90836345fb15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['we', 'always', 'come', 'to', 'paris'],\n",
       " ['the', 'professor', 'is', 'from', 'australia'],\n",
       " ['i', 'live', 'in', 'stanford'],\n",
       " ['he', 'comes', 'from', 'taiwan'],\n",
       " ['the', 'capital', 'of', 'turkey', 'is', 'ankara']]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "  return sentence.lower().split()\n",
    "\n",
    "# Create our training set\n",
    "train_sentences = [sent.lower().split() for sent in corpus]\n",
    "train_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4jzo5tp0Hza"
   },
   "source": [
    "For each training example we have, we should also have a corresponding label. Recall that the goal of our model was to determine which words correspond to a `LOCATION`. That is, we want our model to output `0` for all the words that are not `LOCATION`s and `1` for the ones that are `LOCATION`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3wo1kcMAHFw7",
    "outputId": "ffef4ec0-d693-4137-ba40-f9112db5ea55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set of locations that appear in our corpus\n",
    "locations = set([\"australia\", \"ankara\", \"paris\", \"stanford\", \"taiwan\", \"turkey\"])\n",
    "\n",
    "# Our train labels\n",
    "train_labels = [[1 if word in locations else 0 for word in sent] for sent in train_sentences]\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgVKH9M3RtPx"
   },
   "source": [
    "#### Converting Words to Embeddings\n",
    "\n",
    "Let's look at our training data a little more closely. Each datapoint we have is a sequence of words. On the other hand, we know that machine learning models work with numbers in vectors. How are we going to turn words into numbers? You may be thinking embeddings and you are right!\n",
    "\n",
    "Imagine that we have an embedding lookup table `E`, where each row corresponds to an embedding. That is, each word in our vocabulary would have a corresponding embedding row `i` in this table. Whenever we want to find an embedding for a word, we will follow these steps:\n",
    "1. Find the corresponding index `i` of the word in the embedding table: `word->index`.\n",
    "2. Index into the embedding table and get the embedding: `index->embedding`.\n",
    "\n",
    "Let's look at the first step. We should assign all the words in our vocabulary to a corresponding index. We can do it as follows:\n",
    "1. Find all the unique words in our corpus.\n",
    "2. Assign an index to each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SjTDlfPyVp5z",
    "outputId": "9f36d85f-bc74-4d45-ef79-def80b5a8f6e"
   },
   "source": [
    "Find all the unique words in our corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SjTDlfPyVp5z",
    "outputId": "9f36d85f-bc74-4d45-ef79-def80b5a8f6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'always',\n",
       " 'ankara',\n",
       " 'australia',\n",
       " 'capital',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'from',\n",
       " 'he',\n",
       " 'i',\n",
       " 'in',\n",
       " 'is',\n",
       " 'live',\n",
       " 'of',\n",
       " 'paris',\n",
       " 'professor',\n",
       " 'stanford',\n",
       " 'taiwan',\n",
       " 'the',\n",
       " 'to',\n",
       " 'turkey',\n",
       " 'we'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(w for s in train_sentences for w in s)\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOxnKznOWXSC"
   },
   "source": [
    "`vocabulary` now contains all the words in our corpus. On the other hand, during the test time, we can see words that are not contained in our vocabulary. If we can figure out a way to represent the unknown words, our model can still reason about whether they are a `LOCATION` or not, since we are also looking at the neighboring words for each prediction. \n",
    "\n",
    "We introduce a special token, `<unk>`, to tackle the words that are out of vocabulary. We could pick another string for our unknown token if we wanted. The only requirement here is that our token should be unique: we should only be using this token for unknown words. We will also add this special token to our vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "ygxYuE1DYeR3"
   },
   "outputs": [],
   "source": [
    "vocabulary.add(\"<unk>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bsf4haL94AFu"
   },
   "source": [
    "Earlier we mentioned that our task was called `Word Window Classification` because our model is looking at the surroundings words in addition to the given word when it needs to make a prediction. \n",
    "\n",
    "For example, let's take the sentence \"We always come to Paris\". The corresponding training label for this sentence is `0, 0, 0, 0, 1` since only Paris, the last word, is a `LOCATION`. In one pass (meaning a call to `forward()`), our model will try to generate the correct label for one word. Let's say our model is trying to generate the correct label `1` for `Paris`. If we only allow our model to see `Paris`, but nothing else, we will miss out on the important information that the word `to` often times appears with `LOCATION`s. \n",
    "\n",
    "Word windows allow our model to consider the surrounding `+N` or `-N` words of each word when making a prediction. In our earlier example for `Paris`, if we have a window size of 1, that means our model will look at the words that come immediately before and after `Paris`, which are `to`, and, well, nothing. Now, this raises another issue. `Paris` is at the end of our sentence, so there isn't another word following it. Remember that we define the input dimensions of our `PyTorch` models when we are initializing them. If we set the window size to be `1`, it means that our model will be accepting `3` words in every pass. We cannot have our model expect `2` words from time to time.\n",
    "\n",
    "The solution is to introduce a special token, such as `<pad>`, that will be added to our sentences to make sure that every word has a valid window around them. Similar to `<unk>` token, we could pick another string for our pad token if we wanted, as long as we make sure it is used for a unique purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVQsjYi6ZegI",
    "outputId": "7833a42b-0f2c-4b6a-bda1-3b06503983eb"
   },
   "outputs": [],
   "source": [
    "vocabulary.add(\"<pad>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVQsjYi6ZegI",
    "outputId": "7833a42b-0f2c-4b6a-bda1-3b06503983eb"
   },
   "source": [
    "Function that pads the given sentence.\n",
    "We are introducing this function here as an example.\n",
    "We will be utilizing it later in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVQsjYi6ZegI",
    "outputId": "7833a42b-0f2c-4b6a-bda1-3b06503983eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>', '<pad>', 'we', 'always', 'come', 'to', 'paris', '<pad>', '<pad>']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad_window(sentence, window_size, pad_token=\"<pad>\"):\n",
    "  window = [pad_token] * window_size\n",
    "  return window + sentence + window\n",
    "\n",
    "# Show padding example\n",
    "window_size = 2\n",
    "pad_window(train_sentences[0], window_size=window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqvgWKwSNpAd"
   },
   "source": [
    "Now that our vocabularly is ready, let's assign an index to each of our words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNCTQnKDa4oh",
    "outputId": "54033f5b-e96d-47b0-f93c-bbc12a84bdbe"
   },
   "source": [
    "We are just converting our vocabularly to a list to be able to index into it.\n",
    "Sorting is not necessary, we sort to show an ordered word_to_ind dictionary\n",
    "\n",
    "That being said, we will see that having the index for the padding token\n",
    "be 0 is convenient as some PyTorch functions use it as a default value\n",
    "such as nn.utils.rnn.pad_sequence, which we will cover in a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNCTQnKDa4oh",
    "outputId": "54033f5b-e96d-47b0-f93c-bbc12a84bdbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<unk>': 1,\n",
       " 'always': 2,\n",
       " 'ankara': 3,\n",
       " 'australia': 4,\n",
       " 'capital': 5,\n",
       " 'come': 6,\n",
       " 'comes': 7,\n",
       " 'from': 8,\n",
       " 'he': 9,\n",
       " 'i': 10,\n",
       " 'in': 11,\n",
       " 'is': 12,\n",
       " 'live': 13,\n",
       " 'of': 14,\n",
       " 'paris': 15,\n",
       " 'professor': 16,\n",
       " 'stanford': 17,\n",
       " 'taiwan': 18,\n",
       " 'the': 19,\n",
       " 'to': 20,\n",
       " 'turkey': 21,\n",
       " 'we': 22}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_word = sorted(list(vocabulary))\n",
    "\n",
    "# Creating a dictionary to find the index of a given word\n",
    "word_to_ix = {word: ind for ind, word in enumerate(ix_to_word)}\n",
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "pt-0SK67hMVo",
    "outputId": "a914da1b-6e1c-4309-acd5-bd4a53b7c2b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_word[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELZuteqbdWd1"
   },
   "source": [
    "Great! We are ready to convert our training sentences into a sequence of indices corresponding to each token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNOxip15bMfH",
    "outputId": "01bba9e6-651a-47e8-a3d7-cf5b89ca919d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence is: ['we', 'always', 'come', 'to', 'kuwait']\n",
      "Going from words to indices: [22, 2, 6, 20, 1]\n",
      "Going from indices to words: ['we', 'always', 'come', 'to', '<unk>']\n"
     ]
    }
   ],
   "source": [
    "def convert_tokens_to_indices(sentence, word_to_ix):\n",
    "  \"\"\"Get the index for each token, if it is in our vocabularly, or else get the index for the unknown token.\"\"\"\n",
    "  return [word_to_ix.get(token, word_to_ix[\"<unk>\"]) for token in sentence]\n",
    "\n",
    "# Show an example\n",
    "example_sentence = [\"we\", \"always\", \"come\", \"to\", \"kuwait\"]\n",
    "example_indices = convert_tokens_to_indices(example_sentence, word_to_ix)\n",
    "restored_example = [ix_to_word[ind] for ind in example_indices]\n",
    "\n",
    "print(f\"Original sentence is: {example_sentence}\")\n",
    "print(f\"Going from words to indices: {example_indices}\")\n",
    "print(f\"Going from indices to words: {restored_example}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jsXw8cB1xpH"
   },
   "source": [
    "In the example above, `kuwait` shows up as `<unk>`, because it is not included in our vocabulary. Let's convert our `train_sentences` to `example_padded_indices`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRaKQwSJH-1d",
    "outputId": "7ac54f70-e1ee-4418-a803-42c9ee873074"
   },
   "source": [
    "Converting our sentences to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRaKQwSJH-1d",
    "outputId": "7ac54f70-e1ee-4418-a803-42c9ee873074"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[22, 2, 6, 20, 15],\n",
       " [19, 16, 12, 8, 4],\n",
       " [10, 13, 11, 17],\n",
       " [9, 7, 8, 18],\n",
       " [19, 5, 14, 21, 12, 3]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_indices = [convert_tokens_to_indices(s, word_to_ix) for s in train_sentences]\n",
    "example_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZULjHBjHsEK"
   },
   "source": [
    "##### Embedding Layer\n",
    "\n",
    "Now that we have an index for each word in our vocabularly, we can create an embedding table with `nn.Embedding` class in `PyTorch`. It is called as follows `nn.Embedding(num_words, embedding_dimension)` where `num_words` is the number of words in our vocabulary and the `embedding_dimension` is the dimension of the embeddings we want to have. There is nothing fancy about `nn.Embedding`: it is just a wrapper class around a trainabe `NxE` dimensional tensor, where `N` is the number of words in our vocabulary and `E` is the number of embedding dimensions. This table is initially random, but it will change over time. As we train our network, the gradients will be backpropagated all the way to the embedding layer, and hence our word embeddings would be updated. We will initiliaze the embedding layer we will use for our model in our model, but we are showing an example here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4AgHzv91VXx",
    "outputId": "c718e46d-af30-459a-ed12-510926044d03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-1.3246e+00, -5.1608e-01,  6.0018e-01, -4.7022e-01, -6.0864e-01],\n",
       "         [-4.6192e-02, -1.6457e+00, -6.9602e-01, -7.4029e-01,  3.1428e-01],\n",
       "         [ 1.4156e-01,  1.0348e+00, -6.2644e-01, -5.1509e-01,  6.9029e-01],\n",
       "         [ 2.0403e+00,  1.1366e+00, -4.6184e-01,  1.4200e+00,  8.4852e-01],\n",
       "         [-4.7891e-02,  6.6856e-01,  1.0430e+00,  7.2045e-01, -1.3129e+00],\n",
       "         [ 3.7804e-02, -1.1702e+00, -1.0319e-01,  1.1895e+00,  7.6069e-01],\n",
       "         [-7.4630e-01, -5.8236e-01,  4.8687e-01, -1.0020e+00,  3.2949e-02],\n",
       "         [-4.2920e-01, -9.8180e-01, -6.4206e-01,  8.2659e-01, -3.6460e-01],\n",
       "         [-1.2081e-01, -4.8302e-01,  1.1330e-01,  7.7151e-02, -9.2281e-01],\n",
       "         [-1.2620e+00,  1.0861e+00, -8.7859e-01, -6.8369e-01,  6.6043e-02],\n",
       "         [-7.7380e-04,  1.6206e-01,  1.1960e+00, -1.3062e+00, -1.4040e+00],\n",
       "         [ 9.5265e-02,  3.0573e-01,  4.1506e-01, -7.1741e-01,  2.8340e+00],\n",
       "         [ 1.9535e+00,  2.0487e+00, -1.0880e+00, -2.0479e+00,  8.5127e-01],\n",
       "         [-4.0047e-01, -6.0883e-01, -5.0810e-01, -6.1849e-01, -1.6470e+00],\n",
       "         [-1.0362e+00, -9.7107e-01, -7.2966e-02, -5.4795e-01, -1.1426e+00],\n",
       "         [-4.4875e-01, -3.0454e-02,  3.8303e-01, -4.4770e-02, -2.3120e+00],\n",
       "         [-3.3143e-01,  6.4950e-01,  9.4959e-02, -7.5259e-01, -6.4723e-01],\n",
       "         [-1.2823e+00,  1.9653e+00, -1.1766e+00, -2.5668e+00,  7.0961e-01],\n",
       "         [ 8.1984e-01,  6.2145e-01,  4.2319e-01, -3.3890e-01,  5.1797e-01],\n",
       "         [-1.7459e+00,  1.9296e-01, -6.1033e-01,  1.6323e-01,  3.5332e-01],\n",
       "         [-2.6475e+00, -1.4575e+00, -9.7124e-01,  2.4150e-01, -1.1612e+00],\n",
       "         [ 1.4511e-01,  1.6612e+00,  1.0103e+00,  6.1104e-01,  1.2208e+00],\n",
       "         [-6.0764e-01, -4.5261e-02, -3.5729e-01, -5.7139e-01, -1.4078e+00]],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 5\n",
    "embeds = nn.Embedding(len(vocabulary), embedding_dim)\n",
    "\n",
    "# Printing the parameters in our embedding table\n",
    "list(embeds.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wI7ZTt4OkpPp"
   },
   "source": [
    "To get the word embedding for a word in our vocabulary, all we need to do is to create a lookup tensor. The lookup tensor is just a tensor containing the index we want to look up `nn.Embedding` class expects an index tensor that is of type Long Tensor, so we should create our tensor accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nkldmcepjfh_",
    "outputId": "278c2d7e-acf3-426d-ea29-10f85cf11277"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4488, -0.0305,  0.3830, -0.0448, -2.3120],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = word_to_ix[\"paris\"]\n",
    "index_tensor = torch.tensor(index, dtype=torch.long)\n",
    "paris_embed = embeds(index_tensor)\n",
    "paris_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUsdwBOxm6B4",
    "outputId": "8c4ced79-7235-43f5-ec59-cd33df1d9ca9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4488, -0.0305,  0.3830, -0.0448, -2.3120],\n",
       "        [ 2.0403,  1.1366, -0.4618,  1.4200,  0.8485]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get multiple embeddings at once\n",
    "index_paris = word_to_ix[\"paris\"]\n",
    "index_ankara = word_to_ix[\"ankara\"]\n",
    "indices = [index_paris, index_ankara]\n",
    "indices_tensor = torch.tensor(indices, dtype=torch.long)\n",
    "embeddings = embeds(indices_tensor)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bgSW3LPltkF"
   },
   "source": [
    "Usually, we define the embedding layer as part of our model, which you will see in the later sections of our notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHCXeQOamHU1"
   },
   "source": [
    "#### Batching Sentences\n",
    "\n",
    "We have learned about batches in class. Waiting our whole training corpus to be processed before making an update is costly. On the other hand, updating the parameters after every training example causes the loss to be less stable between updates. To combat these issues, we instead update our parameters after training on a batch of data. This allows us to get a better estimate of the gradient of the global loss. In this section, we will learn how to structure our data into batches using the `torch.util.data.DataLoader` class. \n",
    "\n",
    "We will be calling the `DataLoader` class as follows: `DataLoader(data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)`.  The `batch_size` parameter determines the number of examples per batch. In every epoch, we will be iterating over all the batches using the `DataLoader`. The order of batches is deterministic by default, but we can ask `DataLoader` to shuffle the batches by setting the `shuffle` parameter to `True`. This way we ensure that we don't encounter a bad batch multiple times.\n",
    "\n",
    "If provided, `DataLoader` passes the batches it prepares to the `collate_fn`. We can write a custom function to pass as `collate_fn` parameter in order to perform extra processing. In our case, we will use the `collate_fn` to:\n",
    "1. Pad the sentences to `window_size`.\n",
    "2. Convert the tokens to indices.\n",
    "3. Pad sentences and labels to have the same length. This creates an issue because when calculating the loss, we need to know the actual number of tokens in a given example. We will keep track of these lenghts returning them from `collate_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "OkvvVlo4jgFm"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def custom_collate_fn(batch, window_size, word_to_ix):\n",
    "  # Break our batch into the training examples (x) and labels (y)\n",
    "  x, y = zip(*batch)\n",
    "\n",
    "  # Pad the train examples.\n",
    "  x = [pad_window(s, window_size=window_size) for s in x]\n",
    "\n",
    "  # Convert the train examples into indices.\n",
    "  x = [convert_tokens_to_indices(s, word_to_ix) for s in x]\n",
    "\n",
    "  # We will now pad the examples so that the lengths of all the example in \n",
    "  # one batch are the same, making it possible to do matrix operations. \n",
    "  # We set the batch_first parameter to True so that the returned matrix has \n",
    "  # the batch as the first dimension.\n",
    "  pad_token_ix = word_to_ix[\"<pad>\"]\n",
    "\n",
    "  # pad_sequence function expects the input to be a tensor, so we turn x into one\n",
    "  x = [torch.LongTensor(x_i) for x_i in x]\n",
    "  x_padded = nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=pad_token_ix)\n",
    "\n",
    "  # We also pad the labels. Before doing so, we will record the number \n",
    "  # of labels so that we know how many words existed in each example. \n",
    "  lengths = [len(label) for label in y]\n",
    "  lenghts = torch.LongTensor(lengths)\n",
    "\n",
    "  y = [torch.LongTensor(y_i) for y_i in y]\n",
    "  y_padded = nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=0)\n",
    "\n",
    "  return x_padded, y_padded, lenghts  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93QOZSsMTFNF"
   },
   "source": [
    "Our model will be a window classifier.\n",
    "When we pass this input to our model, it needs to create the windows for each word, make a prediction as to whether the center word is a `LOCATION` or not for each window, put the predictions together and return. \n",
    "\n",
    "We could format our data by breaking it into windows beforehand. Here, we will instead have our model to take care of the formatting. \n",
    "\n",
    "Given that our `window_size` is `N` we want our model to make a prediction on every `2N+1` tokens.\n",
    "\n",
    "That is, if we have a `window_size` of `2`, we want our model to make a prediction on every `5` tokens.\n",
    "If the input has `6` tokens, it will make exactly `6` predictions, since we padded it with `2` tokens on each side.\n",
    "\n",
    "We can create these windows by using `for` loops, but there is a faster `PyTorch` alternative, which is the `unfold(dimension, size, step)` method. We can create the windows we need using this method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0, 22,  2,  6, 20, 15,  0,  0]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sent = convert_tokens_to_indices(pad_window(train_sentences[0], window_size=window_size), word_to_ix)\n",
    "batch = torch.tensor([padded_sent])\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function unfold:\n",
      "\n",
      "unfold(...) method of torch.Tensor instance\n",
      "    unfold(dimension, size, step) -> Tensor\n",
      "    \n",
      "    Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "    :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "    \n",
      "    Step between two slices is given by :attr:`step`.\n",
      "    \n",
      "    If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "    dimension :attr:`dimension` in the returned tensor will be\n",
      "    `(sizedim - size) / step + 1`.\n",
      "    \n",
      "    An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "    \n",
      "    Args:\n",
      "        dimension (int): dimension in which unfolding happens\n",
      "        size (int): the size of each slice that is unfolded\n",
      "        step (int): the step between each slice\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> x = torch.arange(1., 8)\n",
      "        >>> x\n",
      "        tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "        >>> x.unfold(0, 2, 1)\n",
      "        tensor([[ 1.,  2.],\n",
      "                [ 2.,  3.],\n",
      "                [ 3.,  4.],\n",
      "                [ 4.,  5.],\n",
      "                [ 5.,  6.],\n",
      "                [ 6.,  7.]])\n",
      "        >>> x.unfold(0, 2, 2)\n",
      "        tensor([[ 1.,  2.],\n",
      "                [ 3.,  4.],\n",
      "                [ 5.,  6.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(batch.unfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RMZu-pxLVxHQ",
    "outputId": "bf7467d5-632d-4c0a-8bf2-91a24e834f2d"
   },
   "source": [
    "Create the 2 * 2 + 1 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RMZu-pxLVxHQ",
    "outputId": "bf7467d5-632d-4c0a-8bf2-91a24e834f2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows:\n",
      " tensor([[[ 0,  0, 22,  2,  6],\n",
      "         [ 0, 22,  2,  6, 20],\n",
      "         [22,  2,  6, 20, 15],\n",
      "         [ 2,  6, 20, 15,  0],\n",
      "         [ 6, 20, 15,  0,  0]]])\n"
     ]
    }
   ],
   "source": [
    "chunk = batch.unfold(1, window_size*2 + 1, 1)\n",
    "print(f\"Windows:\\n\", chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlDbOpeoSKxd"
   },
   "source": [
    "### Model\n",
    "\n",
    "Now that we have prepared our data, we are ready to build our model. We have learned how to write custom `nn.Module` classes. We will do the same here and put everything we have learned so far together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "JLTU4h76NLYm"
   },
   "outputs": [],
   "source": [
    "class WordWindowClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, hyperparameters, vocab_size, pad_ix=0):\n",
    "    super(WordWindowClassifier, self).__init__()\n",
    "    \n",
    "    \"\"\" Instance variables \"\"\"\n",
    "    self.window_size = hyperparameters[\"window_size\"]\n",
    "    self.embed_dim = hyperparameters[\"embed_dim\"]\n",
    "    self.hidden_dim = hyperparameters[\"hidden_dim\"]\n",
    "    self.freeze_embeddings = hyperparameters[\"freeze_embeddings\"]\n",
    "\n",
    "    \"\"\" Embedding Layer \n",
    "    Takes in a tensor containing embedding indices, and returns the \n",
    "    corresponding embeddings. The output is of dim \n",
    "    (number_of_indices * embedding_dim).\n",
    "\n",
    "    If freeze_embeddings is True, set the embedding layer parameters to be\n",
    "    non-trainable. This is useful if we only want the parameters other than the\n",
    "    embeddings parameters to change. \n",
    "\n",
    "    \"\"\"\n",
    "    self.embeds = nn.Embedding(vocab_size, self.embed_dim, padding_idx=pad_ix)\n",
    "    if self.freeze_embeddings:\n",
    "      self.embed_layer.weight.requires_grad = False\n",
    "\n",
    "    \"\"\" Hidden Layer\n",
    "    \"\"\"\n",
    "    full_window_size = 2 * window_size + 1\n",
    "    self.hidden_layer = nn.Sequential(\n",
    "      nn.Linear(full_window_size * self.embed_dim, self.hidden_dim), \n",
    "      nn.Tanh()\n",
    "    )\n",
    "\n",
    "    \"\"\" Output Layer\n",
    "    \"\"\"\n",
    "    self.output_layer = nn.Linear(self.hidden_dim, 1)\n",
    "\n",
    "    \"\"\" Probabilities \n",
    "    \"\"\"\n",
    "    self.probabilities = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    \"\"\"\n",
    "    Let B:= batch_size\n",
    "        L:= window-padded sentence length\n",
    "        D:= self.embed_dim\n",
    "        S:= self.window_size\n",
    "        H:= self.hidden_dim\n",
    "        \n",
    "    inputs: a (B, L) tensor of token indices\n",
    "    \"\"\"\n",
    "    B, L = inputs.size()\n",
    "\n",
    "    \"\"\"\n",
    "    Reshaping.\n",
    "    Takes in a (B, L) LongTensor\n",
    "    Outputs a (B, L~, S) LongTensor\n",
    "    \"\"\"\n",
    "    # Fist, get our word windows for each word in our input.\n",
    "    token_windows = inputs.unfold(1, 2 * self.window_size + 1, 1)\n",
    "    _, adjusted_length, _ = token_windows.size()\n",
    "\n",
    "    # Good idea to do internal tensor-size sanity checks, at the least in comments!\n",
    "    assert token_windows.size() == (B, adjusted_length, 2 * self.window_size + 1)\n",
    "\n",
    "    \"\"\"\n",
    "    Embedding.\n",
    "    Takes in a torch.LongTensor of size (B, L~, S) \n",
    "    Outputs a (B, L~, S, D) FloatTensor.\n",
    "    \"\"\"\n",
    "    embedded_windows = self.embeds(token_windows)\n",
    "\n",
    "    \"\"\"\n",
    "    Reshaping.\n",
    "    Takes in a (B, L~, S, D) FloatTensor.\n",
    "    Resizes it into a (B, L~, S*D) FloatTensor.\n",
    "    -1 argument \"infers\" what the last dimension should be based on leftover axes.\n",
    "    \"\"\"\n",
    "    embedded_windows = embedded_windows.view(B, adjusted_length, -1)\n",
    "\n",
    "    \"\"\"\n",
    "    Layer 1.\n",
    "    Takes in a (B, L~, S*D) FloatTensor.\n",
    "    Resizes it into a (B, L~, H) FloatTensor\n",
    "    \"\"\"\n",
    "    layer_1 = self.hidden_layer(embedded_windows)\n",
    "\n",
    "    \"\"\"\n",
    "    Layer 2\n",
    "    Takes in a (B, L~, H) FloatTensor.\n",
    "    Resizes it into a (B, L~, 1) FloatTensor.\n",
    "    \"\"\"\n",
    "    output = self.output_layer(layer_1)\n",
    "\n",
    "    \"\"\"\n",
    "    Softmax.\n",
    "    Takes in a (B, L~, 1) FloatTensor of unnormalized class scores.\n",
    "    Outputs a (B, L~, 1) FloatTensor of (log-)normalized class scores.\n",
    "    \"\"\"\n",
    "    output = self.probabilities(output)\n",
    "    output = output.view(B, -1)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avy1fnyAvEcd"
   },
   "source": [
    "### Training\n",
    "\n",
    "We are now ready to put everything together. Let's start with preparing our data and intializing our model. We can then intialize our optimizer and define our loss function. This time, instead of using one of the predefined loss function as we did before, we will define our own loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bInu1VqjHsfj"
   },
   "source": [
    "Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "bInu1VqjHsfj"
   },
   "outputs": [],
   "source": [
    "data = list(zip(train_sentences, train_labels))\n",
    "batch_size = 2\n",
    "shuffle = True\n",
    "window_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we fix the parameters `window_size` and `word_to_ix` of `custom_collate_fn` using `partial`, to obtain a function with a single parameter `batch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RfB0JKL2vZ6p",
    "outputId": "1d689d9e-05fb-4f45-9fb8-9363af241131"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "collate_fn = partial(custom_collate_fn, window_size=window_size, word_to_ix=word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "bInu1VqjHsfj"
   },
   "outputs": [],
   "source": [
    "# Instantiate a DataLoader\n",
    "wwc_loader = DataLoader(data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "\n",
    "# Initialize a model\n",
    "# It is useful to put all the model hyperparameters in a dictionary\n",
    "wwc_hyperparameters = {\n",
    "    \"batch_size\": 4,\n",
    "    \"window_size\": 2,\n",
    "    \"embed_dim\": 25,\n",
    "    \"hidden_dim\": 25,\n",
    "    \"freeze_embeddings\": False,\n",
    "}\n",
    "\n",
    "vocab_size = len(word_to_ix)\n",
    "wwc = WordWindowClassifier(wwc_hyperparameters, vocab_size)\n",
    "\n",
    "# Define an optimizer\n",
    "learning_rate = 0.01\n",
    "wwc_optimizer = torch.optim.SGD(wwc.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define a loss function, which computes to binary cross entropy loss\n",
    "def wwc_loss_function(batch_outputs, batch_labels, batch_lengths):   \n",
    "    # Calculate the loss for the whole batch\n",
    "    bceloss = nn.BCELoss()\n",
    "    loss = bceloss(batch_outputs, batch_labels.float())\n",
    "\n",
    "    # Rescale the loss. Remember that we have used lengths to store the \n",
    "    # number of words in each training example\n",
    "    loss = loss / batch_lengths.sum().float()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHxpxDkFHfQE"
   },
   "source": [
    "Unlike our earlier example, this time instead of passing all of our training data to the model at once in each epoch, we will be utilizing batches. Hence, in each training epoch iteration, we also iterate over the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "QL9IDgIOvHca"
   },
   "outputs": [],
   "source": [
    "# Function that will be called in every epoch\n",
    "def train_epoch(loss_function, optimizer, model, loader):\n",
    "  \n",
    "  # Keep track of the total loss for the batch\n",
    "  total_loss = 0\n",
    "  for batch_inputs, batch_labels, batch_lengths in loader:\n",
    "    # Clear the gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Run a forward pass\n",
    "    outputs = model.forward(batch_inputs)\n",
    "    # Compute the batch loss\n",
    "    loss = loss_function(outputs, batch_labels, batch_lengths)\n",
    "    # Calculate the gradients\n",
    "    loss.backward()\n",
    "    # Update the parameteres\n",
    "    optimizer.step()\n",
    "    total_loss += loss.item()\n",
    "\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QL9IDgIOvHca"
   },
   "source": [
    "Function performing our main training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "QL9IDgIOvHca"
   },
   "outputs": [],
   "source": [
    "def train(loss_function, optimizer, model, loader, num_epochs=10000):\n",
    "\n",
    "  # Iterate through each epoch and call our train_epoch function\n",
    "  for epoch in range(num_epochs):\n",
    "    epoch_loss = train_epoch(loss_function, optimizer, model, loader)\n",
    "    if epoch % 100 == 0: print(epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjf75cnzJ4n6"
   },
   "source": [
    "Let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kav8kwVBJ6XW",
    "outputId": "0bafb3dc-6806-47bc-c5dc-915195e1d05b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27511991560459137\n",
      "0.2496313340961933\n",
      "0.19651339948177338\n",
      "0.1520393155515194\n",
      "0.11476488411426544\n",
      "0.08567661233246326\n",
      "0.05961028765887022\n",
      "0.045259919948875904\n",
      "0.0398957934230566\n",
      "0.040708794724196196\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "train(wwc_loss_function, wwc_optimizer, wwc, wwc_loader, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-k7Pav4LdQJ"
   },
   "source": [
    "### Prediction\n",
    "\n",
    "Let's see how well our model is at making predictions. We can start by creating our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "-v5X69a2Lkbm"
   },
   "outputs": [],
   "source": [
    "test_corpus = [\"She comes from Paris\"]\n",
    "test_sentences = [s.lower().split() for s in test_corpus]\n",
    "test_labels = [[0, 0, 0, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-v5X69a2Lkbm"
   },
   "source": [
    "Create a test loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "-v5X69a2Lkbm"
   },
   "outputs": [],
   "source": [
    "test_data = list(zip(test_sentences, test_labels))\n",
    "test_loader = torch.utils.data.DataLoader(test_data, \n",
    "                                           batch_size=1, \n",
    "                                           shuffle=False, \n",
    "                                           collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlBa8xaNMZgv"
   },
   "source": [
    "Let's loop over our test examples to see how well we are doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGYn8CAoMTjX",
    "outputId": "8d8fd126-ae7e-48e2-fa3e-8eb1a14f99c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 1]])\n",
      "tensor([[0.1766, 0.1638, 0.0806, 0.9324]], grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "for test_instance, labels, _ in test_loader:\n",
    "  outputs = wwc.forward(test_instance)\n",
    "  print(labels)\n",
    "  print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Train and test the Window CLassifier to perform POS Tagging on the Brown corpus, i.e. using<br/>\n",
    "`brown_sents = brown.tagged_sents(categories='news', tagset='universal')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS224N PyTorch Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
