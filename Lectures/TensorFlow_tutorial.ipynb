{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# TensorFlow Tutorial\n",
    "\n",
    "TensorFlow is an end-to-end platform for machine learning. It supports the following:\n",
    "\n",
    "- Multidimensional-array based numeric computation (similar to NumPy.)\n",
    "- GPU and distributed processing\n",
    "- Automatic differentiation\n",
    "- Model construction, training, and export\n",
    "\n",
    "Keras is a high-level API for TensorFlow.\n",
    "Keras provides default training and evaluation loops, `fit()` and `evaluate()`. Their usage is covered in the guide [Training & evaluation with the built-in methods](https://www.tensorflow.org/guide/keras/train_and_evaluate/).\n",
    "\n",
    "If you want to customize the learning algorithm of your model while still leveraging the convenience of `fit()`, you can subclass the `Model` class and implement your own `train_step()` method, which is called repeatedly during `fit()`.\n",
    "\n",
    "Here instead we will write our own training & evaluation loops from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QS7DDTiZGRTo"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NAbSZiaoJ4z"
   },
   "source": [
    "## Get the data\n",
    "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JqFRS6K07jJs"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1Evqx0S22r_"
   },
   "source": [
    "Use `tf.data` to batch and shuffle the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8Iu_quO024c2"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPZ68wASog_I"
   },
   "source": [
    "## Model\n",
    "\n",
    "Build the `tf.keras` model using the Keras [model subclassing API](https://www.tensorflow.org/guide/keras#model_subclassing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "h3IKyzTCDNGo"
   },
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "    self.flatten = Flatten()\n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGih-c2LgbJu"
   },
   "source": [
    "Choose an optimizer and loss function for training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "u48C9WQ774n4"
   },
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JB6A1vcigsIe"
   },
   "source": [
    "Select metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "N0MqHFb4F_qn"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix4mEL65on-w"
   },
   "source": [
    "The `train_step` function is called at each epoch and needs to compute the gradients for backpropagation.<br/>\n",
    "Use `tf.GradientTape` to record the operations run\n",
    "during the forward pass, which enables auto-differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OZACiVqA8KQV"
   },
   "outputs": [],
   "source": [
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # Run the forward pass of the model.\n",
    "    # The operations that the model applies to its inputs\n",
    "    # are being recorded on the GradientTape.\n",
    "\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=True)\n",
    "    loss = loss_fn(labels, predictions)\n",
    "  # Use the gradient tape to automatically retrieve\n",
    "  # the gradients of the trainable variables with respect to the loss.\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss.update_state(loss)\n",
    "  train_accuracy.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8YT7UmFgpjV"
   },
   "source": [
    "The `test_step` function is used for evaluating the model after each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xIKdEzHAJGt7"
   },
   "outputs": [],
   "source": [
    "def test_step(images, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(images, training=False)\n",
    "  t_loss = loss_fn(labels, predictions)\n",
    "\n",
    "  test_loss.update_state(t_loss)\n",
    "  test_accuracy.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's our training loop:\n",
    "\n",
    "- We open a for loop that iterates over epochs\n",
    "- For each epoch, we open a for loop that iterates over the dataset, in batches\n",
    "- For each batch, we open a GradientTape() scope\n",
    "- Inside this scope, we call the model (forward pass) and compute the loss\n",
    "- Outside the scope, we retrieve the gradients of the weights of the model with regard to the loss\n",
    "- Finally, we use the optimizer to update the weights of the model based on the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "i-2pkctU_Ci7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 50.57\n",
      "Loss: 0.1440, Accuracy: 95.69%, Test Loss: 0.0656, Test Accuracy: 97.96%\n",
      "Epoch 2, Time: 50.05\n",
      "Loss: 0.0450, Accuracy: 98.60%, Test Loss: 0.0514, Test Accuracy: 98.22%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start_time = time.time()\n",
    "\n",
    "  # Iterate over the batches of the dataset.\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, Time: {(time.time() - start_time):.2f}\\n'\n",
    "    f'Loss: {train_loss.result():.4f}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100:.2f}%, '\n",
    "    f'Test Loss: {test_loss.result():.4f}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100:.2f}%'\n",
    "  )\n",
    "\n",
    "  # Reset losses and metrics at the end of each epoch\n",
    "  train_loss.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "  train_accuracy.reset_states()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Execution\n",
    "\n",
    "For Graph execution, we turn the `train_step` and `test_step` into graph functions, by decorating the definition with `@tf.function`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OZACiVqA8KQV"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=True)\n",
    "    loss = loss_fn(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss.update_state(loss)\n",
    "  train_accuracy.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8YT7UmFgpjV"
   },
   "source": [
    "Same for the evaluation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xIKdEzHAJGt7"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(images, training=False)\n",
    "  t_loss = loss_fn(labels, predictions)\n",
    "\n",
    "  test_loss.update_state(t_loss)\n",
    "  test_accuracy.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop with the compiled training and test step functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "i-2pkctU_Ci7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 26.52\n",
      "Loss: 0.0250, Accuracy: 99.13%, Test Loss: 0.0513, Test Accuracy: 98.51%\n",
      "Epoch 2, Time: 26.08\n",
      "Loss: 0.0148, Accuracy: 99.51%, Test Loss: 0.0595, Test Accuracy: 98.28%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "  start_time = time.time()\n",
    "\n",
    "  # Iterate over the batches of the dataset.\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "  print(\n",
    "   f'Epoch {epoch + 1}, Time: {(time.time() - start_time):.2f}\\n'\n",
    "    f'Loss: {train_loss.result():.4f}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100:.2f}%, '\n",
    "    f'Test Loss: {test_loss.result():.4f}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100:.2f}%'\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4JfEh7kvx6m"
   },
   "source": [
    "The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the [TensorFlow tutorials](https://www.tensorflow.org/tutorials)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def d():\n",
    "    return tf.add(3, 5)\n",
    "\n",
    "tf_d = tf.function(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.add(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"Add/x\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Add/y\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 5\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Add\"\n",
       "  op: \"AddV2\"\n",
       "  input: \"Add/x\"\n",
       "  input: \"Add/y\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity\"\n",
       "  op: \"Identity\"\n",
       "  input: \"Add\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 987\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_d.get_concrete_function().graph.as_graph_def()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square(x):\n",
    "    return tf.multiply(x, x)\n",
    "\n",
    "square(3.).numpy()   # x^2 = 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dsquare(x):\n",
    "   with tf.GradientTape() as t:\n",
    "    return t.gradient(square(x), x)\n",
    "\n",
    "x = tf.Variable(3.)\n",
    "dsquare(x).numpy()   # 2 * x = 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.8507 - accuracy: 0.9373 - val_loss: 1.2059 - val_accuracy: 0.7958\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 1.5824 - accuracy: 0.9028 - val_loss: 1.6729 - val_accuracy: 0.9061\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 1.9408 - accuracy: 0.8047 - val_loss: 2.1050 - val_accuracy: 0.6502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11f443be50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=3, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3204795), started 0:09:17 ago. (Use '!kill 3204795' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7b40af2dc09d6896\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7b40af2dc09d6896\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "advanced.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
