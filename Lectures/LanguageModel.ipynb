{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Brown corpus if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from nltk.corpus import brown\n",
    "except:\n",
    "    nltk.download('brown')\n",
    "    from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Show the first 20 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(brown.words()[:20])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Number of words in the Brown corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the occurrences\n",
    "We use a dictionary to store the number of occurrences for each word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_counts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in brown.words():\n",
    "    if w in brown_counts:\n",
    "        brown_counts[w] += 1\n",
    "    else:\n",
    "        brown_counts[w] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Show the occurrence count of some words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6344"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_counts['be']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62713"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_counts['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency distribution using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function nltk.FreqDist() builds a frequency distribution, that associates to each word the count of its occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_brown = nltk.FreqDist(brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the frequency of a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7258"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_brown['The']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_brown['Fulton']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the the frequency of 20 words.\n",
    "Notice that we select items 0-19 in the dictionary, which are not kept though in a specific order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " ',',\n",
       " '.',\n",
       " 'of',\n",
       " 'and',\n",
       " 'to',\n",
       " 'a',\n",
       " 'in',\n",
       " 'that',\n",
       " 'is',\n",
       " 'was',\n",
       " 'for',\n",
       " '``',\n",
       " \"''\",\n",
       " 'The',\n",
       " 'with',\n",
       " 'it',\n",
       " 'as',\n",
       " 'he',\n",
       " 'his']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for i, word in enumerate(freq_brown) if i < 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the 20 most frequent words, i.e. this time we take them ordered by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 62713),\n",
       " (',', 58334),\n",
       " ('.', 49346),\n",
       " ('of', 36080),\n",
       " ('and', 27915),\n",
       " ('to', 25732),\n",
       " ('a', 21881),\n",
       " ('in', 19536),\n",
       " ('that', 10237),\n",
       " ('is', 10011),\n",
       " ('was', 9777),\n",
       " ('for', 8841),\n",
       " ('``', 8837),\n",
       " (\"''\", 8789),\n",
       " ('The', 7258),\n",
       " ('with', 7012),\n",
       " ('it', 6723),\n",
       " ('as', 6706),\n",
       " ('he', 6566),\n",
       " ('his', 6466)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_brown.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same using the brown_counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = brown_counts.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sort the brown_counts, according to the value of the count (second element of each item, i.e. item[1]), in reverse order, i.e. highr frequency first.\n",
    "We displat the first 20 items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 62713),\n",
       " (',', 58334),\n",
       " ('.', 49346),\n",
       " ('of', 36080),\n",
       " ('and', 27915),\n",
       " ('to', 25732),\n",
       " ('a', 21881),\n",
       " ('in', 19536),\n",
       " ('that', 10237),\n",
       " ('is', 10011),\n",
       " ('was', 9777),\n",
       " ('for', 8841),\n",
       " ('``', 8837),\n",
       " (\"''\", 8789),\n",
       " ('The', 7258),\n",
       " ('with', 7012),\n",
       " ('it', 6723),\n",
       " ('as', 6706),\n",
       " ('he', 6566),\n",
       " ('his', 6466)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(di, key=lambda item: item[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE Probability from counts\n",
    "Compute probability estimate from counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = len(brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide frequency by number of occurrences of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_prob(word):\n",
    "    return freq_brown[word] / float(word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability estimate of word \"my\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009998346526672592"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_prob('my')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams\n",
    "Collect all bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_bigrams = nltk.bigrams(brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first 10 bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Fulton'),\n",
       " ('Fulton', 'County'),\n",
       " ('County', 'Grand'),\n",
       " ('Grand', 'Jury'),\n",
       " ('Jury', 'said'),\n",
       " ('said', 'Friday'),\n",
       " ('Friday', 'an'),\n",
       " ('an', 'investigation'),\n",
       " ('investigation', 'of'),\n",
       " ('of', \"Atlanta's\")]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[next(brown_bigrams) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function nltk.ConditionalFreqDist() counts frequencies of pairs.\n",
    "When given a list of bigrams, for each word it gives the FreqDist of the following word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfreq_bigram = nltk.ConditionalFreqDist(brown_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequencies of words occurring after word \"my\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'own': 52, 'hand': 19, 'life': 19, 'mind': 19, 'first': 15, 'wife': 14, 'hands': 14, 'eyes': 13, 'father': 13, 'mother': 12, ...})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfreq_bigram[\"my\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 20 most frequent words to come after \"my\", with their frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('own', 52),\n",
       " ('hand', 19),\n",
       " ('life', 19),\n",
       " ('mind', 19),\n",
       " ('first', 15),\n",
       " ('wife', 14),\n",
       " ('hands', 14),\n",
       " ('eyes', 13),\n",
       " ('father', 13),\n",
       " ('mother', 12),\n",
       " ('husband', 12),\n",
       " ('way', 12),\n",
       " ('head', 11),\n",
       " ('left', 8),\n",
       " ('heart', 7),\n",
       " ('point', 7),\n",
       " ('body', 7),\n",
       " ('Uncle', 7),\n",
       " ('best', 6),\n",
       " ('family', 6)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfreq_bigram[\"my\"].most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function nltk.ConditionalProbDist() maps pairs to probabilities.\n",
    "One way in which we can do this is by using Maximum Likelihood Estimation (MLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cprob_bigram = nltk.ConditionalProbDist(cfreq_bigram, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what we find for \"my\": a Maximum Likelihood Estimation-based probability distribution, as a `MLEProbDist` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cprob_my = cprob_bigram[\"my\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the probability of words that can come after \"my\" by using the method `prob()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04478897502153316"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cprob_my.prob('own')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilities in cprob_bigram now form a trained bigram language model.\n",
    "The typical use for a language model is to ask it for the probabillity of a word sequence:\n",
    "\n",
    "$P(how\\ do\\ you\\ do) = P(how) * P(do|how) * P(you|do) * P(do|you)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5639033871961e-09"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_prob(\"how\") * \\\n",
    "    cprob_bigram[\"how\"].prob(\"do\") * \\\n",
    "    cprob_bigram[\"do\"].prob(\"you\") * \\\n",
    "    cprob_bigram[\"you\"].prob(\"do\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language generation\n",
    "We can also use a language model in another way: \n",
    "we can let it generate text at random.\n",
    "This is not so useful, but can be insightful into what it is that the language model has been learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a conditional probability distribution, method `generate` chooses a random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function generate in module nltk.probability:\n",
      "\n",
      "generate(self)\n",
      "    Return a randomly selected sample from this probability distribution.\n",
      "    The probability of returning each sample ``samp`` is equal to\n",
      "    ``self.prob(samp)``.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.probability.ProbDistI.generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mare'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cprob_bigram[\"my\"].generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to generate text at random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gentext(cpd, word, len=20):\n",
    "    print(word, end=' ')\n",
    "    for i in range(len):\n",
    "        word = cpd[word].generate()\n",
    "        print(word, end=' ') \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my hand and these folds . The great value of bottled or childhood . He smiled . Whatever you utilizing vending \n"
     ]
    }
   ],
   "source": [
    "gentext(cprob_bigram, \"my\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of genres are there in the Brown corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try Science Fiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfreq_scifi = nltk.ConditionalFreqDist(nltk.bigrams(brown.words(categories = \"science_fiction\")))\n",
    "cprob_scifi = nltk.ConditionalProbDist(cfreq_scifi, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in temperature and practicality , said Macneff stopped pacing to study the proper living there was a wave of light up to follow the contrary-to-reality thoughts ! ! ! It would \n"
     ]
    }
   ],
   "source": [
    "gentext(cprob_scifi, \"in\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to do this with NLTK books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_cpd(text):\n",
    "    bigrams = nltk.bigrams(text) # nltk.ngrams(text, 2)\n",
    "    return nltk.ConditionalProbDist(nltk.ConditionalFreqDist(bigrams),\n",
    "                                    nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Austin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma_cpd = bigram_cpd(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She was every thing two , my mother is a job of his usual time .\" \" I was plain as \n"
     ]
    }
   ],
   "source": [
    "gentext(emma_cpd, \"She\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sense and Sensibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_cpd = bigram_cpd(nltk.corpus.gutenberg.words('austen-sense.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am rather gave her papers , that grew impatient for Marianne had to own discretion . Design could not it , and their apprehensions as she treated with which Marianne , and to a while . Your sincere affection for as Mrs . \" Dearest Marianne considered what passed on the kingdom ; and there was not attempt at that in it , and looked up stairs . Mrs . It was not the general drift of nothing for thinking it . She thanked him with what SHE could doubt . Mrs . \" Is this act of her opinion \n"
     ]
    }
   ],
   "source": [
    "gentext(sense_cpd, \"I\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_trigrams = nltk.trigrams(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The', 'Fulton', 'County')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(brown_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MLE in module nltk.lm.models:\n",
      "\n",
      "class MLE(nltk.lm.api.LanguageModel)\n",
      " |  MLE(order, vocabulary=None, counter=None)\n",
      " |  \n",
      " |  Class for providing MLE ngram model scores.\n",
      " |  \n",
      " |  Inherits initialization from BaseNgramModel.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MLE\n",
      " |      nltk.lm.api.LanguageModel\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  unmasked_score(self, word, context=None)\n",
      " |      Returns the MLE score for a word given a context.\n",
      " |      \n",
      " |      Args:\n",
      " |      - word is expected to be a string\n",
      " |      - context is expected to be something reasonably convertible to a tuple\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nltk.lm.api.LanguageModel:\n",
      " |  \n",
      " |  __init__(self, order, vocabulary=None, counter=None)\n",
      " |      Creates new LanguageModel.\n",
      " |      \n",
      " |      :param vocabulary: If provided, this vocabulary will be used instead\n",
      " |          of creating a new one when training.\n",
      " |      :type vocabulary: `nltk.lm.Vocabulary` or None\n",
      " |      :param counter: If provided, use this object to count ngrams.\n",
      " |      :type counter: `nltk.lm.NgramCounter` or None\n",
      " |      :param ngrams_fn: If given, defines how sentences in training text are turned to ngram\n",
      " |          sequences.\n",
      " |      :type ngrams_fn: function or None\n",
      " |      :param pad_fn: If given, defines how sentences in training text are padded.\n",
      " |      :type pad_fn: function or None\n",
      " |  \n",
      " |  context_counts(self, context)\n",
      " |      Helper method for retrieving counts for a given context.\n",
      " |      \n",
      " |      Assumes context has been checked and oov words in it masked.\n",
      " |      :type context: tuple(str) or None\n",
      " |  \n",
      " |  entropy(self, text_ngrams)\n",
      " |      Calculate cross-entropy of model for given evaluation text.\n",
      " |      \n",
      " |      :param Iterable(tuple(str)) text_ngrams: A sequence of ngram tuples.\n",
      " |      :rtype: float\n",
      " |  \n",
      " |  fit(self, text, vocabulary_text=None)\n",
      " |      Trains the model on a text.\n",
      " |      \n",
      " |      :param text: Training text as a sequence of sentences.\n",
      " |  \n",
      " |  generate(self, num_words=1, text_seed=None, random_seed=None)\n",
      " |      Generate words from the model.\n",
      " |      \n",
      " |      :param int num_words: How many words to generate. By default 1.\n",
      " |      :param text_seed: Generation can be conditioned on preceding context.\n",
      " |      :param random_seed: A random seed or an instance of `random.Random`. If provided,\n",
      " |          makes the random sampling part of generation reproducible.\n",
      " |      :return: One (str) word or a list of words generated from model.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> from nltk.lm import MLE\n",
      " |      >>> lm = MLE(2)\n",
      " |      >>> lm.fit([[(\"a\", \"b\"), (\"b\", \"c\")]], vocabulary_text=['a', 'b', 'c'])\n",
      " |      >>> lm.fit([[(\"a\",), (\"b\",), (\"c\",)]])\n",
      " |      >>> lm.generate(random_seed=3)\n",
      " |      'a'\n",
      " |      >>> lm.generate(text_seed=['a'])\n",
      " |      'b'\n",
      " |  \n",
      " |  logscore(self, word, context=None)\n",
      " |      Evaluate the log score of this word in this context.\n",
      " |      \n",
      " |      The arguments are the same as for `score` and `unmasked_score`.\n",
      " |  \n",
      " |  perplexity(self, text_ngrams)\n",
      " |      Calculates the perplexity of the given text.\n",
      " |      \n",
      " |      This is simply 2 ** cross-entropy for the text, so the arguments are the same.\n",
      " |  \n",
      " |  score(self, word, context=None)\n",
      " |      Masks out of vocab (OOV) words and computes their model score.\n",
      " |      \n",
      " |      For model-specific logic of calculating scores, see the `unmasked_score`\n",
      " |      method.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.lm.api.LanguageModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.lm.MLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "lm = MLE(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pad each sentence at both ends with \\<s\\> and \\</s\\>, then concatenate all of them and extract the vocabulary of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "train, vocab = padded_everygram_pipeline(3, brown.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(train, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'art and poetry , Homeric critics are often ignorant as well as ethical conflict between two and the way from'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(lm.generate(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
